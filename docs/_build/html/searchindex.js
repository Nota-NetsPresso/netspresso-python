Search.setIndex({"docnames": ["description", "description/api/benchmarker/benchmark/benchmark_model", "description/api/benchmarker/benchmarker", "description/api/compressor/compress/advanced_compression", "description/api/compressor/compress/advanced_compression/compression_method", "description/api/compressor/compress/advanced_compression/manual_compression", "description/api/compressor/compress/advanced_compression/pruning_options", "description/api/compressor/compress/advanced_compression/recommendation_compression", "description/api/compressor/compress/automatic_compression", "description/api/compressor/compress/get_compression", "description/api/compressor/compressor", "description/api/converter/convert/convert_model", "description/api/converter/converter", "description/api/enums/enum/compression_method", "description/api/enums/enum/data_type", "description/api/enums/enum/device_name", "description/api/enums/enum/extension", "description/api/enums/enum/framework", "description/api/enums/enum/group_policy", "description/api/enums/enum/hardware_type", "description/api/enums/enum/layer_norm", "description/api/enums/enum/onnx_operator", "description/api/enums/enum/origin_from", "description/api/enums/enum/policy", "description/api/enums/enum/quantization_mode", "description/api/enums/enum/quantization_precision", "description/api/enums/enum/recommendation_method", "description/api/enums/enum/similarity_metric", "description/api/enums/enum/software_version", "description/api/enums/enum/task", "description/api/enums/enum/task_status", "description/api/enums/enums", "description/api/np/index", "description/api/npqai/base/base", "description/api/npqai/base/dataset/get_dataset", "description/api/npqai/base/dataset/get_datasets", "description/api/npqai/base/dataset/upload_dataset", "description/api/npqai/base/device/get_device_attributes", "description/api/npqai/base/device/get_devices", "description/api/npqai/base/job/get_job", "description/api/npqai/base/job/get_job_summaries", "description/api/npqai/base/model/get_model", "description/api/npqai/base/model/get_models", "description/api/npqai/base/model/upload_model", "description/api/npqai/benchmarker/benchmark_model", "description/api/npqai/benchmarker/benchmarker", "description/api/npqai/benchmarker/download_benchmark_results", "description/api/npqai/benchmarker/download_profile", "description/api/npqai/benchmarker/get_benchmark_task_status", "description/api/npqai/benchmarker/get_inference_task_status", "description/api/npqai/benchmarker/inference_model", "description/api/npqai/benchmarker/update_benchmark_task", "description/api/npqai/converter/convert_model", "description/api/npqai/converter/converter", "description/api/npqai/converter/download_model", "description/api/npqai/converter/get_convert_task_status", "description/api/npqai/converter/update_convert_task", "description/api/npqai/index", "description/api/npqai/options/common", "description/api/npqai/options/compile", "description/api/npqai/options/index", "description/api/npqai/options/profile", "description/api/npqai/options/quantize", "description/api/npqai/quantizer/download_model", "description/api/npqai/quantizer/get_quantize_task_status", "description/api/npqai/quantizer/quantize_model", "description/api/npqai/quantizer/quantizer", "description/api/npqai/quantizer/update_quantize_task", "description/api/quantizer/quantize/automatic_quantization", "description/api/quantizer/quantize/custom_precision_quantization_by_layer_name", "description/api/quantizer/quantize/custom_precision_quantization_by_operator_type", "description/api/quantizer/quantize/recommendation_precision", "description/api/quantizer/quantize/uniform_precision_quantization", "description/api/quantizer/quantizer", "description/api/trainer/train", "description/api/trainer/trainer", "index", "installation"], "filenames": ["description.rst", "description/api/benchmarker/benchmark/benchmark_model.rst", "description/api/benchmarker/benchmarker.rst", "description/api/compressor/compress/advanced_compression.rst", "description/api/compressor/compress/advanced_compression/compression_method.rst", "description/api/compressor/compress/advanced_compression/manual_compression.rst", "description/api/compressor/compress/advanced_compression/pruning_options.rst", "description/api/compressor/compress/advanced_compression/recommendation_compression.rst", "description/api/compressor/compress/automatic_compression.rst", "description/api/compressor/compress/get_compression.rst", "description/api/compressor/compressor.rst", "description/api/converter/convert/convert_model.rst", "description/api/converter/converter.rst", "description/api/enums/enum/compression_method.rst", "description/api/enums/enum/data_type.rst", "description/api/enums/enum/device_name.rst", "description/api/enums/enum/extension.rst", "description/api/enums/enum/framework.rst", "description/api/enums/enum/group_policy.rst", "description/api/enums/enum/hardware_type.rst", "description/api/enums/enum/layer_norm.rst", "description/api/enums/enum/onnx_operator.rst", "description/api/enums/enum/origin_from.rst", "description/api/enums/enum/policy.rst", "description/api/enums/enum/quantization_mode.rst", "description/api/enums/enum/quantization_precision.rst", "description/api/enums/enum/recommendation_method.rst", "description/api/enums/enum/similarity_metric.rst", "description/api/enums/enum/software_version.rst", "description/api/enums/enum/task.rst", "description/api/enums/enum/task_status.rst", "description/api/enums/enums.rst", "description/api/np/index.rst", "description/api/npqai/base/base.rst", "description/api/npqai/base/dataset/get_dataset.rst", "description/api/npqai/base/dataset/get_datasets.rst", "description/api/npqai/base/dataset/upload_dataset.rst", "description/api/npqai/base/device/get_device_attributes.rst", "description/api/npqai/base/device/get_devices.rst", "description/api/npqai/base/job/get_job.rst", "description/api/npqai/base/job/get_job_summaries.rst", "description/api/npqai/base/model/get_model.rst", "description/api/npqai/base/model/get_models.rst", "description/api/npqai/base/model/upload_model.rst", "description/api/npqai/benchmarker/benchmark_model.rst", "description/api/npqai/benchmarker/benchmarker.rst", "description/api/npqai/benchmarker/download_benchmark_results.rst", "description/api/npqai/benchmarker/download_profile.rst", "description/api/npqai/benchmarker/get_benchmark_task_status.rst", "description/api/npqai/benchmarker/get_inference_task_status.rst", "description/api/npqai/benchmarker/inference_model.rst", "description/api/npqai/benchmarker/update_benchmark_task.rst", "description/api/npqai/converter/convert_model.rst", "description/api/npqai/converter/converter.rst", "description/api/npqai/converter/download_model.rst", "description/api/npqai/converter/get_convert_task_status.rst", "description/api/npqai/converter/update_convert_task.rst", "description/api/npqai/index.rst", "description/api/npqai/options/common.rst", "description/api/npqai/options/compile.rst", "description/api/npqai/options/index.rst", "description/api/npqai/options/profile.rst", "description/api/npqai/options/quantize.rst", "description/api/npqai/quantizer/download_model.rst", "description/api/npqai/quantizer/get_quantize_task_status.rst", "description/api/npqai/quantizer/quantize_model.rst", "description/api/npqai/quantizer/quantizer.rst", "description/api/npqai/quantizer/update_quantize_task.rst", "description/api/quantizer/quantize/automatic_quantization.rst", "description/api/quantizer/quantize/custom_precision_quantization_by_layer_name.rst", "description/api/quantizer/quantize/custom_precision_quantization_by_operator_type.rst", "description/api/quantizer/quantize/recommendation_precision.rst", "description/api/quantizer/quantize/uniform_precision_quantization.rst", "description/api/quantizer/quantizer.rst", "description/api/trainer/train.rst", "description/api/trainer/trainer.rst", "index.rst", "installation.md"], "titles": ["API Description", "Benchmark Model", "Benchmarker", "Advanced Compression", "Compression Method", "Manual Compression", "Pruning Options", "Recommendation Compression", "Automatic Compression", "Get Compression Information", "Compressor", "Convert Model", "Converter", "Compression Method", "Data Type", "Device Name", "Extension", "Framework", "Group Policy", "Hardware Type", "LayerNorm", "OnnxOperator", "Origin From", "Policy", "QuantizationMode", "QuantizationPrecision", "Recommendation Method", "SimilarityMetric", "Software Version", "Task", "Task Status", "Enums", "NetsPresso", "Base", "Get Dataset", "Get Datasets", "Upload Dataset", "Get Device Attributes", "Get Devices", "Get Job", "Get Job Summaries", "Get Model", "Get Models", "Upload Model", "Benchmark Model", "Benchmarker", "Download Benchmark Results", "Download Profile", "Get Benchmark Task Status", "Get Inference Task Status", "Inference Model", "Update Benchmark Task", "Convert Model", "Converter", "Download Model", "Get Convert Task Status", "Update Convert Task", "NetsPresso QAI", "Common Options", "Compile Options", "Options", "Profile Options", "Quantize Options", "Download Model", "Get Quantize Task Status", "Quantize Model", "Quantizer", "Update Quantize Task", "Automatic Quantization", "Custom Precision Quantization by Layer Name", "Custom Precision Quantization by Operator Type", "Recommendation precision", "Plain Quantization", "Quantizer", "Train", "Trainer", "Welcome to NetsPresso!", "Installation"], "terms": {"trainer": [0, 32, 74, 76], "train": [5, 32], "compressor": [0, 5, 6, 7, 8, 9, 32, 76], "compress": [21, 31, 32], "quantiz": [0, 32, 57, 60, 71, 76], "convert": [0, 1, 5, 32, 57, 71, 76], "benchmark": [0, 32, 50, 57, 76], "enum": [0, 1, 5, 7, 11, 32, 58, 59, 61, 62, 68, 69, 70, 71, 72, 74, 76], "task": [31, 32, 44, 45, 52, 53, 57, 58, 65, 66, 74], "framework": [7, 8, 11, 31, 32, 59], "extens": [31, 32, 59], "origin": [4, 31, 32], "from": [1, 5, 7, 8, 9, 11, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 52, 54, 63, 65, 68, 69, 70, 71, 72, 74], "method": [3, 6, 9, 31, 32, 68, 72], "recommend": [3, 31, 32, 73, 77], "polici": [5, 7, 9, 31, 32], "group": [31, 32], "layernorm": [5, 7, 21, 31, 32], "devic": [1, 11, 31, 32, 44, 50, 52, 57, 65, 77], "name": [1, 5, 7, 9, 11, 31, 32, 36, 38, 43, 44, 50, 52, 65, 73, 74, 77], "softwar": [1, 11, 31, 32], "version": [1, 5, 11, 31, 32, 77], "hardwar": [1, 15, 31, 32, 65, 70], "type": [1, 5, 7, 8, 11, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 55, 56, 64, 65, 67, 68, 69, 71, 72, 73, 74], "statu": [5, 31, 32, 44, 45, 52, 53, 57, 65, 66, 69, 70], "data": [11, 31, 32, 36, 47, 50, 52, 65, 74, 77], "quantizationmod": [31, 32], "quantizationprecis": [31, 32, 68, 69, 70, 71, 72], "similaritymetr": [31, 32, 68, 69, 70, 71, 72], "onnxoper": [31, 32], "benchmark_model": [1, 44], "self": [1, 5, 7, 8, 9, 11, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 63, 64, 65, 67, 68, 69, 70, 71, 72], "input_model_path": [1, 5, 7, 8, 11, 44, 50, 52, 65, 68, 69, 70, 71, 72], "str": [1, 5, 7, 8, 9, 11, 34, 37, 38, 39, 40, 41, 43, 44, 46, 48, 49, 50, 52, 54, 55, 58, 59, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 74], "target_device_nam": [1, 11, 44, 50, 52], "devicenam": [1, 11, 15], "target_software_vers": [1, 11], "softwarevers": [1, 11, 28], "none": [1, 5, 7, 9, 11, 14, 18, 20, 36, 38, 40, 43, 44, 50, 52, 58, 59, 61, 62, 65, 68, 69, 70, 71, 72, 74], "target_hardware_typ": 1, "hardwaretyp": [1, 19], "wait_until_don": [1, 11, 68, 69, 70, 71, 72], "bool": [1, 11, 44, 50, 52, 59, 61, 68, 69, 70, 71, 72, 74], "true": [1, 11, 44, 50, 52, 61, 65, 68, 69, 70, 71, 72, 74], "sleep_interv": [1, 11, 68, 69, 70, 71, 72], "int": [1, 5, 7, 8, 11, 35, 40, 42, 52, 59, 61, 68, 69, 70, 71, 72, 74], "30": [1, 11, 68, 69, 70, 71, 72, 74], "benchmarkermetadata": [1, 44, 51], "specifi": [1, 11, 58, 68, 69, 70, 71, 72, 74], "paramet": [1, 11, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74], "The": [1, 4, 5, 6, 7, 8, 11, 34, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74], "file": [1, 5, 7, 8, 11, 68, 69, 70, 71, 72], "path": [1, 5, 7, 8, 11, 44, 50, 52, 65, 68, 69, 70, 71, 72, 74, 77], "where": [1, 5, 7, 8, 11, 21, 68, 69, 70, 71, 72], "i": [1, 4, 5, 6, 7, 8, 11, 44, 52, 65, 68, 69, 70, 71, 72, 74], "locat": [1, 5, 7, 8, 11, 68, 69, 70, 71, 72], "target": [1, 11, 58, 65, 68, 69, 70, 71, 72], "union": [1, 11, 44, 50, 52, 61, 65, 68, 71, 74], "option": [0, 1, 3, 8, 9, 11, 21, 44, 50, 52, 57, 65, 68, 69, 70, 71, 72, 74, 76], "requir": [1, 5, 8, 11, 70], "one": [1, 4, 11], "jetson": [1, 11, 15], "acceler": 1, "process": [1, 6, 69, 71, 74], "infer": [1, 44, 45, 57, 61, 74], "If": [1, 4, 5, 6, 7, 8, 11, 21, 68, 69, 70, 71, 72, 74, 77], "wait": [1, 11, 68, 69, 70, 71, 72], "result": [1, 7, 11, 45, 57, 68, 69, 70, 72, 74], "befor": [1, 5, 11, 68, 69, 70, 71, 72], "return": [1, 4, 7, 8, 11, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 55, 56, 64, 65, 67, 68, 69, 70, 71, 72, 74], "function": [1, 4, 7, 11, 68, 69, 70, 71, 72], "fals": [1, 5, 7, 11, 52, 59, 61, 68, 69, 70, 71, 72, 74], "request": [1, 11, 68, 69, 70, 72], "immedi": [1, 11, 68, 69, 70, 71, 72], "rais": [1, 5, 7, 8, 11, 68, 69, 70, 71, 72, 74], "e": [1, 5, 7, 8, 11, 68, 69, 70, 71, 72, 74, 77], "an": [1, 5, 7, 8, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 49, 50, 58, 59, 61, 62, 68, 69, 70, 71, 72, 76, 77], "error": [1, 5, 7, 8, 11, 30, 68, 69, 70, 71, 72], "occur": [1, 5, 7, 8, 11, 68, 69, 70, 71, 72], "dure": [1, 11, 68, 69, 70, 71, 72], "metadata": [1, 5, 7, 8, 11, 44, 51, 52, 56, 65, 67, 68, 69, 70, 71, 72], "netspresso": [0, 1, 5, 6, 7, 8, 9, 11, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 61, 65, 68, 69, 70, 71, 72, 74, 77], "import": [1, 4, 5, 6, 7, 8, 9, 11, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 65, 68, 69, 70, 71, 72, 74], "email": [1, 5, 7, 8, 9, 11, 68, 69, 70, 71, 72, 74, 76], "your_email": [1, 5, 7, 8, 9, 11, 68, 69, 70, 71, 72, 74], "password": [1, 5, 7, 8, 9, 11, 68, 69, 70, 71, 72, 74], "your_password": [1, 5, 7, 8, 9, 11, 68, 69, 70, 71, 72, 74], "benchmarker_v2": 1, "benchmark_task": 1, "output": [1, 6, 7, 8, 11, 68, 69, 70, 71, 72, 74], "tensorrt_jetson_agx_orin_jetpack_5_0_1": [1, 11], "trt": 1, "jetson_agx_orin": [1, 11, 15], "jetpack_5_0_1": [1, 11, 28], "model": [2, 4, 6, 7, 8, 12, 45, 53, 57, 59, 61, 62, 66, 68, 69, 70, 71, 72, 74], "manual": 3, "prune": [3, 5, 7], "differ": [4, 6, 70], "each": [4, 6, 7, 69, 70, 71], "about": [4, 5, 7, 74], "measur": [4, 6], "layer": [4, 7, 9, 44, 68, 71, 72, 73], "automat": [4, 10, 73], "base": [0, 4, 5, 7, 8, 57, 58, 59, 61, 62, 65, 68, 70, 71, 72, 74, 76], "certain": [4, 11, 68, 69, 70, 71, 72], "graphic": 4, "connect": [4, 6], "queri": 4, "kei": 4, "have": 4, "least": 4, "inform": [4, 5, 6, 7, 10, 74, 77], "attent": 4, "score": 4, "while": [4, 5, 6, 7, 8, 44, 52, 65, 68, 69], "preserv": [4, 6, 68], "overal": 4, "which": [4, 6], "can": [4, 6, 8, 69, 70, 76], "independ": [4, 6], "ar": [4, 5, 6, 68], "elimin": 4, "inter": 4, "head": [4, 74], "redund": 4, "click": [4, 5, 7], "link": [4, 5, 7], "more": [4, 5, 6, 7, 8, 76], "us": [4, 5, 6, 7, 11, 44, 50, 52, 65, 68, 69, 70, 71, 72, 74, 76], "repres": [4, 6, 65], "correspond": [4, 6, 7], "In": [4, 5], "other": [4, 44, 74], "word": 4, "thi": [4, 5, 6, 7, 68, 69, 70, 71, 72, 77], "magnitud": [4, 7], "weight": [4, 5, 6, 65, 68, 69, 70, 71, 72], "geometr": 4, "median": 4, "remov": [4, 6, 7], "sum": [4, 18, 21, 23], "energi": 4, "It": [4, 8, 74], "comput": [4, 58], "featur": 4, "map": [4, 50, 52, 65, 70, 74], "determin": 4, "": [4, 6, 58, 74, 77], "relev": 4, "For": [4, 5, 6, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 55, 58, 59, 61, 62, 63, 64, 65, 77], "reason": [4, 6], "portion": 4, "dataset": [4, 5, 7, 11, 50, 52, 57, 68, 69, 70, 71, 72, 74], "need": [4, 76], "chosen": 4, "through": 4, "without": 4, "you": [4, 5, 7, 8, 76, 77], "appli": [4, 5, 6, 7, 68, 69, 70, 72], "your": [4, 8, 44, 76, 77], "own": 4, "select": [4, 7, 70], "less": [4, 21], "better": 4, "perform": [4, 7, 8, 65, 69, 70, 71], "By": [4, 5], "approxim": 4, "decompos": 4, "convolut": [4, 6, 70], "4d": 4, "kernel": 4, "tensor": 4, "two": 4, "factor": [4, 7], "matric": 4, "small": 4, "core": 4, "pointwis": 4, "fulli": 4, "sequenc": 4, "four": 4, "2d": 4, "upload_model": [5, 43], "input_shap": [5, 7, 8, 52], "list": [5, 7, 8, 9, 35, 37, 38, 40, 42, 44, 50, 52, 58, 59, 61, 65, 68, 69, 70, 71, 72, 74], "dict": [5, 7, 8, 9, 52, 68, 69, 70, 71, 72, 74], "pytorch": [5, 7, 8, 17, 59, 77], "modelbas": 5, "default": [5, 7, 8, 11, 61, 74], "object": [5, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 50, 52, 58, 61, 62, 65, 69, 70], "class": [5, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 58, 59, 61, 62, 74], "sourc": [5, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 58, 59, 61, 62, 74], "enumer": [5, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 58, 59, 61, 62], "descript": [5, 7, 76], "tensorflow_kera": [5, 17], "tensorflow": [5, 7, 17, 59, 77], "kera": [5, 7], "graphmodul": [5, 7, 8], "onnx": [5, 7, 11, 16, 17, 43, 59, 68, 69, 70, 71, 72], "support": [5, 7, 74], "1": [5, 6, 7, 8, 9, 28, 52, 61, 62, 65, 74, 77], "11": [5, 9, 77], "x": [5, 7, 77], "10": [5, 9, 74, 77], "defin": [5, 68], "should": [5, 6, 74], "format": [5, 74], "being": 5, "how": [5, 76], "guid": 5, "convers": [5, 11, 52], "pt": [5, 7, 8, 16, 59, 74], "must": 5, "contain": [5, 6, 69, 70, 74, 77], "onli": [5, 7, 68], "dictionari": [5, 74], "also": [5, 76], "structur": [5, 7], "do": [5, 68, 71, 76], "state_dict": 5, "h5": [5, 16, 59], "zip": [5, 16], "2": [5, 6, 7, 9, 28, 65, 74, 76, 77], "3": [5, 7, 8, 9, 52, 61, 62, 65, 74, 77], "8": [5, 7, 9, 74, 77], "custom": [5, 22, 73], "includ": [5, 6, 69, 70], "save_weight": 5, "pleas": [5, 6, 74, 76, 77], "savedmodel": 5, "same": [5, 6], "dynam": [5, 11, 68, 69, 70, 71, 72], "static": [5, 11, 68, 69, 70, 71, 72], "batch": [5, 6, 7, 8, 11, 68, 69, 70, 71, 72, 74], "channel": [5, 7, 8, 9], "height": 5, "768": [5, 6], "width": 5, "1024": [5, 9], "dimens": [5, 7, 8], "current": [5, 74], "singl": [5, 52, 74], "compressor_v2": [5, 7, 8, 9], "sample_model": [5, 7, 8, 11, 68, 69, 70, 71, 72], "mobilenetv1": 5, "224": [5, 7, 8], "select_compression_method": 5, "model_id": [5, 41], "compression_method": [5, 7, 9], "compressionmethod": [5, 7, 13], "client": [5, 7, 52, 65], "v2": [5, 7], "schema": [5, 7], "reshape_channel_axi": [5, 6, 7, 9], "averag": [5, 7, 9, 18, 23], "layer_norm": [5, 7, 9], "standard_scor": [5, 7, 20], "group_polici": [5, 7, 9], "grouppolici": [5, 7, 18], "step_siz": [5, 6, 7], "step_op": [5, 7], "stepop": [5, 7], "round": [5, 7, 21], "revers": [5, 7], "responseselectmethod": 5, "id": [5, 34, 39, 41, 48, 49, 55, 64, 74, 77], "pr_l2": [5, 7, 9, 13], "l2": [5, 7], "norm": [5, 7], "pr_gm": [5, 7, 13], "gm": [5, 7], "pr_nn": [5, 7, 13], "nuclear": [5, 7], "pr_snp": [5, 7, 13], "neuron": [5, 6, 7], "level": [5, 7, 68, 69, 70, 72], "pr_id": [5, 13], "index": [5, 6], "fd_tk": [5, 7, 13], "tucker": [5, 7], "decomposit": [5, 7], "fd_svd": [5, 7, 13], "singular": [5, 7], "fd_cp": [5, 13], "cp": 5, "learn": [5, 7, 74, 76], "tss_norm": [5, 7, 9, 20], "count": [5, 7, 18], "compression_info": 5, "your_uploaded_model_id": 5, "compressioninfo": [5, 9], "available_lay": [5, 9], "availablelay": [5, 9], "conv1": [5, 9], "32": [5, 6, 9], "0": [5, 6, 7, 8, 9, 28, 35, 40, 42, 61, 65, 68, 69, 70, 71, 74, 77], "conv2": [5, 9], "64": [5, 6, 9], "128": [5, 9], "256": [5, 9], "4": [5, 9, 28, 44, 61, 74], "5": [5, 6, 7, 8, 9, 28, 62], "512": [5, 9, 65, 74], "6": [5, 6, 9, 28], "7": [5, 9], "9": [5, 9, 77], "12": [5, 6, 9], "original_model_id": [5, 9], "compressed_model_id": [5, 9], "compression_id": [5, 9], "number": [5, 6, 74], "rang": [5, 7, 8, 21], "float": [5, 7, 8, 9, 68, 71], "ratio": [5, 6, 9], "num": 5, "out": 5, "rank": [5, 7], "min": [5, 21], "compress_model": 5, "output_dir": [5, 7, 8, 11, 44, 52, 65, 68, 69, 70, 71, 72, 74], "dataset_path": [5, 7, 11, 65, 68, 69, 70, 71, 72], "compressormetadata": [5, 7, 8], "provid": [5, 69, 76], "local": [5, 7, 8, 11, 68, 69, 70, 71, 72], "save": [5, 7, 8, 11, 46, 52, 54, 63, 65, 68, 69, 70, 71, 72, 74], "compressed_model": [5, 7, 8], "graphmodule_manu": 5, "declar": [5, 74], "ai_model_id": 5, "allow": [6, 69, 70], "filter": [6, 7], "ident": [6, 21], "given": [6, 7, 8, 46, 47, 71], "criteria": 6, "To": [6, 77], "calcul": 6, "detail": [6, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 55, 58, 59, 61, 62, 63, 64, 65, 69], "refer": [6, 77], "follow": [6, 8, 77], "document": 6, "its": 6, "summat": 6, "valu": [6, 7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 58, 59, 61, 62], "necessari": [6, 8], "compar": 6, "shape": [6, 7, 8, 11, 21, 52, 65, 68, 69, 70, 71, 72], "argument": 6, "ensur": 6, "all": [6, 58, 72], "minimum": 6, "amount": [6, 7], "perserv": 6, "represnt": 6, "ex": 6, "consid": 6, "input": [6, 7, 8, 11, 44, 50, 52, 65, 68, 69, 70, 71, 72, 74], "197": 6, "when": [6, 69, 70, 71], "50": [6, 35, 40, 42], "remain": [6, 7, 68], "after": 6, "align": 6, "nearest": 6, "size": [6, 21, 65, 69, 71, 74], "adjust": 6, "alwai": 6, "next": 6, "directli": 6, "affect": 6, "closest": 6, "lower": [6, 69], "impact": 6, "No": 6, "exact": 6, "recommendation_compress": 7, "recommendation_method": 7, "recommendationmethod": [7, 26], "recommendation_ratio": 7, "recommendationopt": 7, "min_num_of_valu": 7, "slamp": [7, 26], "adapt": 7, "sparsiti": 7, "vbmf": [7, 26], "variat": 7, "bayesian": 7, "matrix": [7, 70], "recommended_method": 7, "g": [7, 11, 68, 69, 70, 71, 72, 74], "20": 7, "img": [7, 8, 65], "src": [7, 8], "http": [7, 8, 77], "latex": [7, 8], "codecog": [7, 8], "com": [7, 8, 77], "svg": [7, 8], "imag": [7, 8, 52, 65, 74, 76], "space": [7, 8], "titl": [7, 8], "calibr": [7, 52], "control": [7, 69], "doesn": 7, "t": [7, 77], "meet": [7, 68, 71], "user": [7, 69, 70], "want": [7, 76], "add": [7, 21], "subtract": 7, "accord": 7, "graphmodule_recommend": 7, "automatic_compress": 8, "compression_ratio": 8, "As": 8, "increas": 8, "get": [8, 10, 33, 45, 53, 57, 66, 71], "lighter": 8, "faster": 8, "greater": [8, 21], "lost": 8, "accuraci": [8, 65, 68, 69], "therefor": 8, "find": 8, "appropri": 8, "might": 8, "few": 8, "trial": 8, "avail": 8, "pytorch_automatic_compression_1": 8, "get_compress": 9, "responsecompress": 9, "ani": 9, "factori": 9, "compressed_info": 9, "your_compression_id": 9, "c65ca574": 9, "08ab": 9, "4a42": 9, "9e82": 9, "a222bd089b2c": 9, "59375": 9, "25": 9, "34375": 9, "33203125": 9, "55859375": 9, "56640625": 9, "697265625": 9, "70703125": 9, "580078125": 9, "vailablelay": 9, "51953125": 9, "517578125": 9, "7734375": 9, "0234375": 9, "advanc": 10, "convert_model": [11, 52], "target_framework": 11, "target_data_typ": 11, "datatyp": [11, 14], "fp16": [11, 14, 59, 69, 70], "input_lay": [11, 68, 69, 70, 71, 72], "inputlay": 11, "convertermetadata": [11, 52, 56], "folder": [11, 68, 69, 70, 71, 72], "target_devic": 11, "inputshap": [11, 68, 69, 70, 72], "converter_v2": 11, "conversion_task": 11, "test": [11, 68, 69, 70, 71, 72], "tensorrt": [11, 17, 59], "fp32": 14, "int8": [14, 25, 52, 59, 62, 65, 68, 69, 70, 71, 72], "raspberry_pi_5": 15, "raspberrypi5": 15, "raspberry_pi_4b": 15, "raspberrypi4b": 15, "raspberry_pi_3b_plu": 15, "raspberrypi3bplu": 15, "raspberry_pi_3b": 15, "raspberrypi3b": 15, "raspberry_pi_2b": 15, "raspberrypi2b": 15, "raspberry_pi_zero_w": 15, "raspberrypi": 15, "zerow": 15, "raspberry_pi_zero_2w": 15, "zero2w": 15, "renesas_rz_v2l": 15, "rzv2l_avnet": 15, "renesas_rz_v2m": 15, "rzv2m": 15, "renesas_ra8d1": 15, "renesa": 15, "ra8d1": 15, "jetson_nano": 15, "nano": 15, "jetson_tx2": 15, "tx2": 15, "jetson_xavi": 15, "xavier": 15, "jetson_nx": 15, "nx": 15, "agx": 15, "orin": 15, "jetson_orin_nano": 15, "aws_t4": 15, "aw": 15, "t4": 15, "intel_xeon_w_2233": 15, "intel": 15, "xeon": 15, "alif_ensemble_e7_devkit_gen2": 15, "ensembl": 15, "e7": 15, "devkit": 15, "gen2": 15, "arm_ethos_u_seri": 15, "arm": 15, "virtual": 15, "etho": 15, "u": [15, 76], "seri": 15, "nxp_imx93": 15, "nxp_imx93_ethos_u65": 15, "arduino_nicla_vis": 15, "jetson_devic": 15, "raspberry_pi_devic": 15, "renesas_devic": 15, "nvidia_graphic_card": 15, "intel_devic": 15, "available_int8_devic": 15, "only_int8_devic": 15, "saved_model": 17, "openvino": 17, "tensorflow_lit": [17, 59], "drpai": 17, "classmethod": 17, "create_compressor_liter": 17, "create_launcher_liter": 17, "helium": 19, "linear_sc": 20, "softmax_norm": 20, "adagrad": 21, "momentum": 21, "zipmap": 21, "treeensembleclassifi": 21, "svmregressor": 21, "linearclassifi": 21, "dictvector": 21, "categorymapp": 21, "castmap": 21, "stringsplit": 21, "adam": 21, "gelu": 21, "scaler": 21, "affinegrid": 21, "bitwiseor": 21, "bitwiseand": 21, "mish": 21, "melweightmatrix": 21, "blackmanwindow": 21, "gradient": 21, "hammingwindow": 21, "hannwindow": 21, "sequencemap": 21, "gridsampl": 21, "castlik": 21, "optionalhasel": 21, "softmaxcrossentropyloss": 21, "greaterorequ": 21, "lessorequ": 21, "celu": 21, "imput": 21, "sequencelength": 21, "optionalgetel": 21, "sequenceat": 21, "sequenceconstruct": 21, "gathernd": 21, "scatternd": 21, "gatherel": 21, "cumsum": 21, "roialign": 21, "nonmaxsuppress": 21, "dequantizelinear": 21, "dft": 21, "quantizelinear": 21, "qlinearconv": 21, "convinteg": 21, "det": 21, "qlinearmatmul": 21, "matmulinteg": 21, "normal": [21, 61], "randomnorm": 21, "isinf": 21, "Or": [21, 76], "concatfromsequ": 21, "constant": 21, "featurevector": 21, "mul": 21, "max": 21, "gru": 21, "groupnorm": 21, "mod": 21, "log": [21, 74], "argmax": 21, "reducemax": 21, "split": 21, "reducemin": 21, "deformconv": 21, "maxpool": 21, "sign": [21, 74], "cast": 21, "prelu": 21, "randomuniform": 21, "pad": [21, 65], "nonzero": 21, "ceil": 21, "tan": 21, "Not": 21, "clip": 21, "reducel2": 21, "neg": 21, "linearregressor": 21, "bitwisexor": 21, "conv": [21, 70], "stringconcat": 21, "ab": 21, "softplu": 21, "maxunpool": 21, "tfidfvector": 21, "convtranspos": 21, "sequenceempti": 21, "And": 21, "flatten": 21, "reducelogsum": 21, "einsum": 21, "reducelogsumexp": 21, "sub": 21, "floor": 21, "randomuniformlik": 21, "maxroipool": 21, "concat": 21, "sigmoid": 21, "sequenceinsert": 21, "softmax": 21, "dynamicquantizelinear": 21, "instancenorm": 21, "loop": 21, "lppool": 21, "argmin": 21, "equal": 21, "labelencod": 21, "splittosequ": 21, "uniqu": 21, "bitshift": 21, "averagepool": 21, "slice": 21, "dropout": 21, "exp": 21, "eyelik": 21, "lstm": 21, "arrayfeatureextractor": 21, "matmul": [21, 70], "leakyrelu": 21, "reducemean": 21, "reversesequ": 21, "batchnorm": 21, "lpnormal": 21, "gemm": 21, "onehot": 21, "bernoulli": 21, "negativeloglikelihoodloss": 21, "rnn": 21, "globallppool": 21, "gather": 21, "hardswish": 21, "mean": 21, "isnan": 21, "regexfullmatch": 21, "asin": 21, "onehotencod": 21, "depthtospac": 21, "div": 21, "softsign": 21, "globalmaxpool": 21, "reciproc": 21, "meanvariancenorm": 21, "reducel1": 21, "relu": 21, "scatterel": 21, "reducesum": 21, "elu": 21, "reshap": 21, "imagedecod": 21, "selu": 21, "constantofshap": 21, "globalaveragepool": 21, "hardsigmoid": 21, "logsoftmax": 21, "spacetodepth": 21, "treeensembleregressor": 21, "bitwisenot": 21, "reducesumsquar": 21, "sqrt": 21, "col2im": 21, "randomnormallik": 21, "multinomi": 21, "expand": 21, "squeez": 21, "stft": 21, "upsampl": 21, "tanh": 21, "tile": 21, "topk": 21, "lrn": 21, "unsqueez": 21, "thresholdedrelu": 21, "sequenceeras": 21, "xor": 21, "aco": 21, "pow": 21, "atan": 21, "svmclassifi": 21, "co": 21, "sin": 21, "transpos": [21, 65], "reduceprod": 21, "scan": 21, "scatter": 21, "centercroppad": 21, "sinh": 21, "asinh": 21, "binar": 21, "trilu": 21, "acosh": 21, "cosh": 21, "stringnorm": 21, "atanh": 21, "shrink": 21, "hardmax": 21, "erf": 21, "resiz": [21, 65, 74], "originfrom": 22, "npm": 22, "automatic_quant": [24, 68, 69, 70, 71], "uniform_precision_quant": [24, 72], "custom_precision_quant": 24, "advanced_quant": 24, "recommend_quant": 24, "float16": [25, 59, 61], "float32": [25, 61], "snr": [27, 68, 69, 70, 71, 72], "jetpack_4_4_1": 28, "b50": 28, "jetpack_4_6": 28, "b199": 28, "b118": 28, "jetpack_5_0_2": 28, "b231": 28, "jetpack_6_0": 28, "b52": 28, "image_classif": 29, "classif": [29, 74], "object_detect": [29, 74], "detect": 29, "semantic_segment": 29, "segment": 29, "taskstatu": 30, "in_queu": 30, "in_progress": 30, "finish": [30, 44, 52, 65, 71], "timeout": 30, "user_cancel": 30, "weight_precis": [68, 69, 70, 71, 72], "activation_precis": [68, 69, 70, 71, 72], "metric": [44, 68, 69, 70, 71, 72], "threshold": [68, 69, 70, 71], "quantizermetadata": [68, 69, 70, 71, 72], "precis": [68, 72, 73], "activ": [65, 68, 69, 70, 71, 72], "evalu": [68, 71], "qualiti": [68, 69, 70, 71, 72], "unquant": 68, "quantization_result": [68, 69, 70, 72], "sample_dataset": [68, 69, 70, 71, 72], "pickle_calibration_dataset_128x128": [68, 69, 70, 71, 72], "npy": [68, 69, 70, 71, 72], "custom_precision_quantization_by_layer_nam": 69, "precision_by_layer_nam": 69, "precisionbylay": 69, "default_weight_precis": [69, 70], "default_activation_precis": [69, 70], "over": 69, "enabl": [69, 70], "assign": [], "specif": [69, 70, 71], "within": [69, 70], "item": 69, "enhanc": 69, "compat": [69, 77], "optim": [69, 74], "keep": 69, "critic": 69, "higher": 69, "explicitli": [69, 70], "A": 74, "precision_by_operator_typ": 70, "desir": [69, 70], "entri": [69, 70], "backbon": 69, "conv_first": 69, "block": 69, "act": 69, "mul_output_0": 69, "oper": 73, "recommendation_metadata": [69, 70, 71], "get_recommendation_precis": [69, 70, 71], "recommendation_precis": [69, 70, 71], "load_recommendation_precision_result": [69, 70, 71], "recommendation_result_path": [69, 70, 71], "custom_precision_quantization_by_operator_typ": 70, "precisionbyoper": 70, "highli": 70, "customiz": 70, "indic": 70, "multipl": 70, "etc": [69, 70], "fine": 70, "tune": 70, "strategi": 70, "capabl": 70, "fall": 70, "back": 70, "analyz": 71, "set": [71, 74], "help": [65, 71], "balanc": [61, 71], "below": [71, 77], "receiv": 71, "start": [52, 65, 71], "interv": [69, 70, 71], "second": [69, 70, 71], "between": [69, 70, 71], "check": [69, 70, 71, 77], "uniform": 72, "uniformli": 72, "plain": 73, "token_handl": 74, "tokenhandl": 74, "yaml_path": 74, "netspressobas": 74, "set_dataset_config": 74, "root_path": 74, "train_imag": 74, "train_label": 74, "label": 74, "valid_imag": 74, "valid": 74, "valid_label": 74, "test_imag": 74, "test_label": 74, "id_map": 74, "configur": 74, "root": 74, "directori": [46, 52, 65, 74], "rel": 74, "val": 74, "set_model_config": 74, "model_nam": 74, "img_siz": [52, 65, 74], "use_pretrain": 74, "load_head": 74, "fx_model_path": 74, "optimizer_path": 74, "whether": [44, 50, 52, 74], "pre": 74, "load": [44, 74], "fx": 74, "valueerror": 74, "set_fx_model": 74, "setup": 74, "set_training_config": 74, "schedul": 74, "epoch": 74, "batch_siz": 74, "rate": 74, "total": 74, "sampl": [65, 74], "set_augmentation_config": 74, "train_transform": 74, "inference_transform": 74, "augment": 74, "transform": 74, "set_logging_config": 74, "project_id": 74, "tensorboard": 74, "csv": 74, "stdout": 74, "save_optimizer_st": 74, "validation_epoch": 74, "save_checkpoint_epoch": 74, "project": 74, "experi": 74, "_": 74, "segmentation_segform": 74, "ignor": 74, "standard": 74, "state": [40, 74], "checkpoint": [74, 77], "resum": 74, "frequenc": 74, "set_environment_config": 74, "seed": 74, "num_work": 74, "environ": 74, "random": 74, "multi": 74, "worker": 74, "loader": 74, "gpu": [58, 61, 74, 77], "project_nam": 74, "trainermetadata": 74, "separ": 74, "comma": 74, "adamw": 74, "cosineannealingwarmrestartswithcustomwarmup": 74, "config": 74, "traffic_sign_config_exampl": 74, "traffic": 74, "prohibitori": 74, "danger": 74, "mandatori": 74, "print": [44, 52, 65, 74], "available_model": 74, "efficientform": 74, "yolox": 74, "lr": 74, "6e": 74, "warmup_epoch": 74, "40": 74, "16": 74, "training_result": 74, "project_sampl": 74, "temp": 74, "hparam": 74, "yaml": 74, "project_retrain_sampl": 74, "instal": 76, "account": 76, "creat": 76, "prerequisit": 76, "pypi": 76, "stabl": 76, "github": 76, "docker": 76, "compos": 76, "build": 76, "api": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 55, 58, 59, 61, 62, 63, 64, 65, 76], "join": 76, "our": 76, "discuss": 76, "forum": 76, "feedback": 76, "share": 76, "case": 76, "talk": 76, "nota": [76, 77], "here": 76, "via": 76, "ai": [44, 76], "phone": 76, "82": 76, "555": 76, "8659": 76, "python": 77, "13": 77, "pip": 77, "edit": 77, "mode": 77, "git": 77, "clone": 77, "pynetspresso": 77, "cd": 77, "repositori": 77, "dockerfil": 77, "yml": 77, "latest": 77, "run": [44, 52, 65, 77], "command": 77, "export": 77, "tag": 77, "v": 77, "cat": 77, "servic": 77, "port": 77, "dev": 77, "bash": 77, "ipc": 77, "host": 77, "TO": 77, "IN": 77, "p": 77, "50001": 77, "50002": 77, "50003": 77, "50004": 77, "param": [], "qai": [0, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 55, 58, 59, 61, 62, 63, 64, 65, 76], "profileopt": [44, 61], "compute_unit": [44, 50, 52, 58, 59, 61], "dequantize_output": [44, 50, 61], "tflite_deleg": [44, 50, 61], "tflite_opt": [44, 50, 61], "qnn_option": [44, 50, 61], "onnx_opt": [44, 50, 61], "onnx_execution_provid": [44, 50, 61], "max_profiler_iter": [44, 50, 61], "100": [44, 50, 61, 65], "max_profiler_tim": [44, 50, 61], "600": [44, 50, 61], "job_nam": [44, 50, 52, 65], "retri": [44, 50, 52], "hub": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 55, 58, 59, 61, 62, 63, 64, 65], "see": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 54, 55, 58, 59, 61, 62, 63, 64, 65], "submit_profile_job": 44, "job": [44, 46, 47, 50, 52, 54, 57, 63, 65], "fail": [44, 50, 52], "success": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 50, 52, 65], "download_benchmark_result": 46, "profilejob": [46, 47], "artifacts_dir": 46, "profilejobresult": 46, "download_result": 46, "download_profil": 47, "retriev": 47, "app": [], "aihub": [], "qualcomm": 44, "doc": [], "html": [], "qai_hub": [52, 65], "get_benchmark_task_statu": [44, 48], "benchmark_task_id": 48, "jobstatu": [48, 49, 55, 64], "get_inference_task_statu": 49, "inference_task_id": 49, "inference_model": 50, "ndarrai": [50, 52, 65], "inferenceopt": [50, 61], "inferencejob": 50, "submit_inference_job": 50, "update_benchmark_task": [44, 51], "download": [45, 53, 57, 66], "profil": [45, 57, 60], "updat": [45, 53, 57, 66], "pathlib": [52, 65], "tupl": 52, "np_qai": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 61, 65], "compil": [52, 57, 60], "compileopt": [52, 59], "target_runtim": [52, 59], "runtim": [52, 59], "tflite": [52, 59], "output_nam": [52, 59], "truncate_64bit_tensor": [52, 59], "truncate_64bit_io": [52, 59], "force_channel_last_input": [52, 59], "force_channel_last_output": [52, 59], "quantize_full_typ": [52, 59], "quantize_weight_typ": [52, 59], "quantize_io": [52, 59], "quantize_io_typ": [52, 59], "qnn_graph_nam": [52, 59], "qnn_context_binary_vtcm": [52, 59], "qnn_context_binary_optimization_level": [52, 59], "single_compil": 52, "calibration_data": [52, 65], "numpi": [52, 65], "submit_compile_job": 52, "step": 52, "download_model": [54, 63], "compilejob": 54, "filenam": [54, 63], "download_target_model": [54, 63], "get_convert_task_statu": [52, 55], "convert_task_id": 55, "update_convert_task": [52, 56], "quantizejob": 63, "get_quantize_task_statu": [64, 65], "quantize_task_id": 64, "quantize_model": 65, "weights_dtyp": 65, "quantizedtyp": 65, "activations_dtyp": 65, "quantizeopt": [62, 65], "range_schem": [62, 65], "rangeschem": [62, 65], "auto": [62, 65], "npqaiquantizermetadata": [65, 67], "submit_quantize_job": 65, "update_quantize_task": [65, 67], "common": [57, 60, 61], "computeunit": [44, 52, 58, 59, 61], "npu": [44, 52, 58], "cpu": 58, "commonopt": [58, 59, 61], "nonetyp": 61, "onnxruntim": 59, "aimet": 59, "coreml": 59, "qnn": [59, 61], "qnn_lib_aarch64_android": 59, "qnn_context_binari": 59, "precompiled_qnn_onnx": 59, "quantizefulltyp": [52, 59], "int16": [59, 62], "w8a16": 59, "w4a8": 59, "w4a16": 59, "quantizeweighttyp": 59, "to_cli_str": [59, 61, 62], "tflitedeleg": 61, "executionmod": 61, "graphoptimizationlevel": 61, "onnxqnnhtpperformancemod": 61, "onnxexecutionprovid": 61, "qnnloglevel": 61, "qnngraphprior": 61, "qnngpuprecis": 61, "qnngpuperformancemod": 61, "qnndspperformancemod": 61, "qnndspencod": 61, "tfliteqnnhtpperformancemod": 61, "qnnhtpprecis": 61, "qnnhtpoptimizationstrategi": 61, "gpuinferenceprefer": 61, "gpuinferenceprior": 61, "nnapiexecutionprefer": 61, "contexterrorreportingoptionslevel": 61, "prioriti": 61, "contextgpuperformancehint": 61, "contexthtpperformancemod": 61, "defaultgraphgpuprecis": 61, "defaultgraphhtpoptimizationtyp": 61, "defaultgraphhtpprecis": 61, "onnxopt": 61, "onnxqnnopt": 61, "tfliteopt": [44, 61], "tfliteqnnopt": 61, "tflitegpuv2opt": 61, "tflitennapiopt": 61, "qnnoption": 61, "profilecommonopt": 61, "quantizeprecis": [62, 65], "qnn_gpu": 61, "nnapi": 61, "nnapi_gpu": 61, "xnnpack": 61, "sequenti": 61, "parallel": 61, "disable_al": 61, "enable_bas": 61, "enable_extend": 61, "enable_al": 61, "low_power_sav": 61, "power_sav": 61, "high_power_sav": 61, "low_balanc": 61, "high_perform": 61, "sustained_high_perform": 61, "burst": 61, "directml": 61, "k_log_off": 61, "klogoff": 61, "k_log_level_error": 61, "kloglevelerror": 61, "k_log_level_warn": 61, "kloglevelwarn": 61, "k_log_level_info": 61, "kloglevelinfo": 61, "k_log_level_verbos": 61, "kloglevelverbos": 61, "k_log_level_debug": 61, "klogleveldebug": 61, "k_qnn_priority_default": 61, "kqnnprioritydefault": 61, "k_qnn_priority_low": 61, "kqnnprioritylow": 61, "k_qnn_priority_norm": 61, "kqnnprioritynorm": 61, "k_qnn_priority_normal_high": 61, "kqnnprioritynormalhigh": 61, "k_qnn_priority_high": 61, "kqnnpriorityhigh": 61, "k_qnn_priority_undefin": 61, "kqnnpriorityundefin": 61, "k_gpu_user_provid": 61, "kgpuuserprovid": 61, "k_gpu_fp32": 61, "kgpufp32": 61, "k_gpu_fp16": 61, "kgpufp16": 61, "k_gpu_hybrid": 61, "kgpuhybrid": 61, "k_gpu_default": 61, "kgpudefault": 61, "k_gpu_high": 61, "kgpuhigh": 61, "k_gpu_norm": 61, "kgpunorm": 61, "k_gpu_low": 61, "kgpulow": 61, "k_dsp_low_power_sav": 61, "kdsplowpowersav": 61, "k_dsp_power_sav": 61, "kdsppowersav": 61, "k_dsp_high_power_sav": 61, "kdsphighpowersav": 61, "k_dsp_low_balanc": 61, "kdsplowbalanc": 61, "k_dsp_balanc": 61, "kdspbalanc": 61, "k_dsp_high_perform": 61, "kdsphighperform": 61, "k_dps_sustained_high_perform": 61, "kdspsustainedhighperform": 61, "k_dsp_burst": 61, "kdspburst": 61, "k_dsp_static": 61, "kdspstatic": 61, "k_dsp_dynam": 61, "kdspdynam": 61, "k_htp_low_power_sav": 61, "khtplowpowersav": 61, "k_htp_power_sav": 61, "khtppowersav": 61, "k_htp_high_power_sav": 61, "khtphighpowersav": 61, "k_htp_low_balanc": 61, "khtplowbalanc": 61, "k_htp_balanc": 61, "khtpbalanc": 61, "k_htp_high_perform": 61, "khtphighperform": 61, "k_htp_sustained_high_perform": 61, "khtpsustainedhighperform": 61, "k_htp_burst": 61, "khtpburst": 61, "k_htp_quantiz": 61, "khtpquantiz": 61, "k_htp_fp16": 61, "khtpfp16": 61, "k_htp_optimize_for_infer": 61, "khtpoptimizeforinfer": 61, "k_htp_optimize_for_prepar": 61, "khtpoptimizeforprepar": 61, "tflite_gpu_inference_preference_fast_single_answ": 61, "tflite_gpu_inference_preference_sustained_spe": 61, "tflite_gpu_inference_preference_balanc": 61, "tflite_gpu_inference_priority_max_precis": 61, "tflite_gpu_inference_priority_min_lat": 61, "tflite_gpu_inference_priority_min_memory_usag": 61, "k_low_pow": 61, "klowpow": 61, "k_fast_single_answ": 61, "kfastsingleansw": 61, "k_sustained_spe": 61, "ksustainedspe": 61, "brief": 61, "low": 61, "normal_high": 61, "high": 61, "extreme_power_sav": 61, "hybrid": 61, "user_provid": 61, "finalize_optimization_flag": 61, "execution_mod": 61, "intra_op_num_thread": 61, "inter_op_num_thread": 61, "enable_memory_pattern": 61, "enable_cpu_memory_arena": 61, "graph_optimization_level": 61, "qnn_htp_performance_mod": 61, "qnn_htp_graph_optimization_mod": 61, "qnn_enable_htp_fp16_precis": 61, "enable_fallback": 61, "invoke_interpreter_on_cold_load": 61, "allow_fp32_as_fp16": 61, "force_opengl": 61, "number_of_thread": [44, 61], "release_dynamic_tensor": 61, "qnn_log_level": 61, "qnn_graph_prior": 61, "qnn_gpu_precis": 61, "qnn_gpu_performance_mod": 61, "qnn_dsp_performance_mod": 61, "qnn_dsp_encod": 61, "qnn_htp_precis": 61, "qnn_htp_optimization_strategi": 61, "qnn_htp_use_conv_hmx": 61, "qnn_htp_use_fold_relu": 61, "qnn_htp_vtcm_size": 61, "qnn_htp_num_hvx_thread": 61, "gpu_inference_prefer": 61, "gpu_inference_priority1": 61, "gpu_inference_priority2": 61, "gpu_inference_priority3": 61, "gpu_max_delegated_partit": 61, "nnapi_execution_prefer": 61, "nnapi_max_number_delegated_partit": 61, "nnapi_allow_fp16": 61, "default_graph_htp_optimization_valu": 61, "context_async_execution_queue_depth_numer": 61, "context_enable_graph": 61, "context_error_reporting_options_level": 61, "context_error_reporting_options_storage_limit": 61, "context_memory_limit_hint": 61, "context_prior": 61, "context_gpu_performance_hint": 61, "context_gpu_use_gl_buff": 61, "context_htp_performance_mod": 61, "default_graph_prior": 61, "default_graph_gpu_precis": 61, "default_graph_gpu_disable_memory_optim": 61, "default_graph_gpu_disable_node_optim": 61, "default_graph_gpu_disable_queue_record": 61, "default_graph_htp_disable_fold_relu_activation_into_conv": 61, "default_graph_htp_num_hvx_thread": 61, "default_graph_htp_optimization_typ": 61, "default_graph_htp_precis": 61, "default_graph_htp_disable_short_depth_conv_on_hmx": 61, "default_graph_htp_vtcm_s": 61, "handle_tflite_opt": 61, "handle_onnx_opt": 61, "handle_qnn_opt": 61, "handle_common_opt": 61, "mse_minim": 62, "min_max": 62, "int4": 62, "unit": 58, "qai\uc5d0\uc11c": [], "\uc0ac\uc6a9\ub418\ub294": [], "\ub2e4\uc591\ud55c": [], "\uc635\uc158\ub4e4\uc5d0": [], "\ub300\ud55c": [], "\uc124\uba85\uc785\ub2c8\ub2e4": [], "\ubaa8\ub4e0": [], "\uc635\uc158\uc5d0\uc11c": [], "\uacf5\ud1b5\uc801\uc73c\ub85c": [], "\uae30\ubcf8": [], "\uc124\uc815\ub4e4\uc785\ub2c8\ub2e4": [], "\ub4f1": [], "\uc5f0\uc0b0": [], "\uc7a5\uce58": [], "\uc124\uc815": [], "\uc608\uc81c": [], "\ubcf4\uae30": [], "\ubaa8\ub378": [], "\ucef4\ud30c\uc77c": [], "\uc2dc": [], "\uc635\uc158\ub4e4\uc785\ub2c8\ub2e4": [], "\ud0c0\uac9f": [], "\ub7f0\ud0c0\uc784": [], "\uc785\ub825": [], "\ud504\ub808\uc784\uc6cc\ud06c": [], "\ubcc0\ud658": [], "\ud504\ub85c\ud30c\uc77c\ub9c1": [], "\uac01": [], "\ub7f0\ud0c0\uc784\ubcc4": [], "\uc138\ubd80": [], "\ubc18\ubcf5": [], "\ud69f\uc218": [], "\uc2dc\uac04": [], "\uc81c\ud55c": [], "\ubca4\uce58\ub9c8\ud0b9": [], "\uc591\uc790\ud654": [], "\ubc94\uc704": [], "\ubc29\uc2dd": [], "\uc815\ubc00\ub3c4": [], "npqai": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 65], "qai_hub_api_token": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 65], "your_qai_hub_api_token": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 65], "api_token": [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 65], "convert_opt": 52, "640": [52, 65], "your_input_model_path": [44, 52, 65], "your_output_dir": [44, 52, 65], "your_job_nam": [44, 52, 65], "device_nam": [44, 52, 65], "qcs6490": [44, 52], "proxi": [44, 52], "converted_result": 52, "monitor": [44, 52, 65], "convert_task_info": 52, "convert_task_uuid": 52, "complet": [44, 52, 65], "break": [44, 52, 65], "els": [44, 52, 65], "still": [44, 52, 65], "your_device_nam": 65, "inputs_arrai": 65, "quantized_result": 65, "quantize_info": 65, "quantize_task_uuid": 65, "cv2": 65, "glob": 65, "np": 65, "inferenc": 65, "preprocessor": 65, "preprocess_list": 65, "interpol": 65, "bilinear": 65, "max_siz": 65, "resize_criteria": 65, "long": 65, "fill": 65, "114": 65, "num_dataset": 65, "image_path": 65, "f": 65, "jpg": 65, "imread": 65, "cvtcolor": 65, "color_bgr2rgb": 65, "append": 65, "arrai": 65, "your_dataset_path": [36, 65], "benchmark_opt": 44, "benchmark_result": 44, "benchmark_task_info": 44, "benchmark_task_uuid": 44, "visit": 44, "like": 44, "memori": 44, "usag": 44, "time": 44, "analysi": 44, "visual": 44, "good": 65, "improv": 65, "retain": 65, "upload": 33, "get_dataset": [34, 35], "your_dataset_id": 34, "upload_dataset": 36, "attribut": [33, 38], "device_attribut": 37, "get_device_attribut": 37, "get_devic": 38, "get_job": 39, "your_job_id": 39, "job_summari": 40, "get_job_summari": 40, "summari": 33, "get_model": [41, 42], "your_model_id": 41, "your_model_path": 43, "dataset_id": 34, "offset": [35, 40, 42], "limit": [35, 40, 42], "even": [35, 42], "older": [35, 42], "string": 37, "o": 38, "job_id": 39, "creator": 40, "jobtyp": 40, "jobsummari": 40, "torch": 43, "jit": 43, "topleveltracedmodul": 43, "coremltool": 43, "mlmodel": 43, "modelproto": 43, "byte": 43, "exampl": []}, "objects": {"netspresso.benchmarker.__init__.BenchmarkerV2": [[1, 0, 1, "", "benchmark_model"]], "netspresso.compressor.__init__.CompressorV2": [[8, 0, 1, "", "automatic_compression"], [5, 0, 1, "", "compress_model"], [9, 0, 1, "", "get_compression"], [7, 0, 1, "", "recommendation_compression"], [5, 0, 1, "", "select_compression_method"], [5, 0, 1, "", "upload_model"]], "netspresso.converter.__init__.ConverterV2": [[11, 0, 1, "", "convert_model"]], "netspresso.enums.__init__": [[13, 1, 1, "", "CompressionMethod"], [14, 1, 1, "", "DataType"], [15, 1, 1, "", "DeviceName"], [16, 1, 1, "", "Extension"], [17, 1, 1, "", "Framework"], [18, 1, 1, "", "GroupPolicy"], [19, 1, 1, "", "HardwareType"], [20, 1, 1, "", "LayerNorm"], [21, 1, 1, "", "OnnxOperator"], [22, 1, 1, "", "OriginFrom"], [23, 1, 1, "", "Policy"], [24, 1, 1, "", "QuantizationMode"], [25, 1, 1, "", "QuantizationPrecision"], [26, 1, 1, "", "RecommendationMethod"], [27, 1, 1, "", "SimilarityMetric"], [28, 1, 1, "", "SoftwareVersion"], [29, 1, 1, "", "Task"], [30, 1, 1, "", "TaskStatus"]], "netspresso.enums.__init__.CompressionMethod": [[13, 2, 1, "", "FD_CP"], [13, 2, 1, "", "FD_SVD"], [13, 2, 1, "", "FD_TK"], [13, 2, 1, "", "PR_GM"], [13, 2, 1, "", "PR_ID"], [13, 2, 1, "", "PR_L2"], [13, 2, 1, "", "PR_NN"], [13, 2, 1, "", "PR_SNP"]], "netspresso.enums.__init__.DataType": [[14, 2, 1, "", "FP16"], [14, 2, 1, "", "FP32"], [14, 2, 1, "", "INT8"], [14, 2, 1, "", "NONE"]], "netspresso.enums.__init__.DeviceName": [[15, 2, 1, "", "ALIF_ENSEMBLE_E7_DEVKIT_GEN2"], [15, 2, 1, "", "ARDUINO_NICLA_VISION"], [15, 2, 1, "", "ARM_ETHOS_U_SERIES"], [15, 2, 1, "", "AVAILABLE_INT8_DEVICES"], [15, 2, 1, "", "AWS_T4"], [15, 2, 1, "", "INTEL_DEVICES"], [15, 2, 1, "", "INTEL_XEON_W_2233"], [15, 2, 1, "", "JETSON_AGX_ORIN"], [15, 2, 1, "", "JETSON_DEVICES"], [15, 2, 1, "", "JETSON_NANO"], [15, 2, 1, "", "JETSON_NX"], [15, 2, 1, "", "JETSON_ORIN_NANO"], [15, 2, 1, "", "JETSON_TX2"], [15, 2, 1, "", "JETSON_XAVIER"], [15, 2, 1, "", "NVIDIA_GRAPHIC_CARDS"], [15, 2, 1, "", "NXP_iMX93"], [15, 2, 1, "", "ONLY_INT8_DEVICES"], [15, 2, 1, "", "RASPBERRY_PI_2B"], [15, 2, 1, "", "RASPBERRY_PI_3B"], [15, 2, 1, "", "RASPBERRY_PI_3B_PLUS"], [15, 2, 1, "", "RASPBERRY_PI_4B"], [15, 2, 1, "", "RASPBERRY_PI_5"], [15, 2, 1, "", "RASPBERRY_PI_DEVICES"], [15, 2, 1, "", "RASPBERRY_PI_ZERO_2W"], [15, 2, 1, "", "RASPBERRY_PI_ZERO_W"], [15, 2, 1, "", "RENESAS_DEVICES"], [15, 2, 1, "", "RENESAS_RA8D1"], [15, 2, 1, "", "RENESAS_RZ_V2L"], [15, 2, 1, "", "RENESAS_RZ_V2M"]], "netspresso.enums.__init__.Extension": [[16, 2, 1, "", "H5"], [16, 2, 1, "", "ONNX"], [16, 2, 1, "", "PT"], [16, 2, 1, "", "ZIP"]], "netspresso.enums.__init__.Framework": [[17, 2, 1, "", "DRPAI"], [17, 2, 1, "", "ONNX"], [17, 2, 1, "", "OPENVINO"], [17, 2, 1, "", "PYTORCH"], [17, 2, 1, "", "TENSORFLOW"], [17, 2, 1, "", "TENSORFLOW_KERAS"], [17, 2, 1, "", "TENSORFLOW_LITE"], [17, 2, 1, "", "TENSORRT"], [17, 3, 1, "", "create_compressor_literal"], [17, 3, 1, "", "create_launcher_literal"]], "netspresso.enums.__init__.GroupPolicy": [[18, 2, 1, "", "AVERAGE"], [18, 2, 1, "", "COUNT"], [18, 2, 1, "", "NONE"], [18, 2, 1, "", "SUM"]], "netspresso.enums.__init__.HardwareType": [[19, 2, 1, "", "HELIUM"]], "netspresso.enums.__init__.LayerNorm": [[20, 2, 1, "", "LINEAR_SCALING"], [20, 2, 1, "", "NONE"], [20, 2, 1, "", "SOFTMAX_NORM"], [20, 2, 1, "", "STANDARD_SCORE"], [20, 2, 1, "", "TSS_NORM"]], "netspresso.enums.__init__.OnnxOperator": [[21, 2, 1, "", "Abs"], [21, 2, 1, "", "Acos"], [21, 2, 1, "", "Acosh"], [21, 2, 1, "", "Adagrad"], [21, 2, 1, "", "Adam"], [21, 2, 1, "", "Add"], [21, 2, 1, "", "AffineGrid"], [21, 2, 1, "", "And"], [21, 2, 1, "", "ArgMax"], [21, 2, 1, "", "ArgMin"], [21, 2, 1, "", "ArrayFeatureExtractor"], [21, 2, 1, "", "Asin"], [21, 2, 1, "", "Asinh"], [21, 2, 1, "", "Atan"], [21, 2, 1, "", "Atanh"], [21, 2, 1, "", "AveragePool"], [21, 2, 1, "", "BatchNormalization"], [21, 2, 1, "", "Bernoulli"], [21, 2, 1, "", "Binarizer"], [21, 2, 1, "", "BitShift"], [21, 2, 1, "", "BitwiseAnd"], [21, 2, 1, "", "BitwiseNot"], [21, 2, 1, "", "BitwiseOr"], [21, 2, 1, "", "BitwiseXor"], [21, 2, 1, "", "BlackmanWindow"], [21, 2, 1, "", "Cast"], [21, 2, 1, "", "CastLike"], [21, 2, 1, "", "CastMap"], [21, 2, 1, "", "CategoryMapper"], [21, 2, 1, "", "Ceil"], [21, 2, 1, "", "Celu"], [21, 2, 1, "", "CenterCropPad"], [21, 2, 1, "", "Clip"], [21, 2, 1, "", "Col2Im"], [21, 2, 1, "", "Compress"], [21, 2, 1, "", "Concat"], [21, 2, 1, "", "ConcatFromSequence"], [21, 2, 1, "", "Constant"], [21, 2, 1, "", "ConstantOfShape"], [21, 2, 1, "", "Conv"], [21, 2, 1, "", "ConvInteger"], [21, 2, 1, "", "ConvTranspose"], [21, 2, 1, "", "Cos"], [21, 2, 1, "", "Cosh"], [21, 2, 1, "", "CumSum"], [21, 2, 1, "", "DFT"], [21, 2, 1, "", "DeformConv"], [21, 2, 1, "", "DepthToSpace"], [21, 2, 1, "", "DequantizeLinear"], [21, 2, 1, "", "Det"], [21, 2, 1, "", "DictVectorizer"], [21, 2, 1, "", "Div"], [21, 2, 1, "", "Dropout"], [21, 2, 1, "", "DynamicQuantizeLinear"], [21, 2, 1, "", "ERF"], [21, 2, 1, "", "Einsum"], [21, 2, 1, "", "Elu"], [21, 2, 1, "", "Equal"], [21, 2, 1, "", "Exp"], [21, 2, 1, "", "Expand"], [21, 2, 1, "", "EyeLike"], [21, 2, 1, "", "FeatureVectorizer"], [21, 2, 1, "", "Flatten"], [21, 2, 1, "", "Floor"], [21, 2, 1, "", "GRU"], [21, 2, 1, "", "Gather"], [21, 2, 1, "", "GatherElements"], [21, 2, 1, "", "GatherND"], [21, 2, 1, "", "Gelu"], [21, 2, 1, "", "Gemm"], [21, 2, 1, "", "GlobalAveragePool"], [21, 2, 1, "", "GlobalLpPool"], [21, 2, 1, "", "GlobalMaxPool"], [21, 2, 1, "", "Gradient"], [21, 2, 1, "", "Greater"], [21, 2, 1, "", "GreaterOrEqual"], [21, 2, 1, "", "GridSample"], [21, 2, 1, "", "GroupNormalization"], [21, 2, 1, "", "HammingWindow"], [21, 2, 1, "", "HannWindow"], [21, 2, 1, "", "HardSigmoid"], [21, 2, 1, "", "HardSwish"], [21, 2, 1, "", "Hardmax"], [21, 2, 1, "", "Identity"], [21, 2, 1, "", "If"], [21, 2, 1, "", "ImageDecoder"], [21, 2, 1, "", "Imputer"], [21, 2, 1, "", "InstanceNormalization"], [21, 2, 1, "", "IsInf"], [21, 2, 1, "", "IsNaN"], [21, 2, 1, "", "LRN"], [21, 2, 1, "", "LSTM"], [21, 2, 1, "", "LabelEncoder"], [21, 2, 1, "", "LayerNormalization"], [21, 2, 1, "", "LeakyRelu"], [21, 2, 1, "", "Less"], [21, 2, 1, "", "LessOrEqual"], [21, 2, 1, "", "LinearClassifier"], [21, 2, 1, "", "LinearRegressor"], [21, 2, 1, "", "Log"], [21, 2, 1, "", "LogSoftmax"], [21, 2, 1, "", "Loop"], [21, 2, 1, "", "LpNormalization"], [21, 2, 1, "", "LpPool"], [21, 2, 1, "", "MatMul"], [21, 2, 1, "", "MatMulInteger"], [21, 2, 1, "", "Max"], [21, 2, 1, "", "MaxPool"], [21, 2, 1, "", "MaxRoiPool"], [21, 2, 1, "", "MaxUnpool"], [21, 2, 1, "", "Mean"], [21, 2, 1, "", "MeanVarianceNormalization"], [21, 2, 1, "", "MelWeightMatrix"], [21, 2, 1, "", "Min"], [21, 2, 1, "", "Mish"], [21, 2, 1, "", "Mod"], [21, 2, 1, "", "Momentum"], [21, 2, 1, "", "Mul"], [21, 2, 1, "", "Multinomial"], [21, 2, 1, "", "Neg"], [21, 2, 1, "", "NegativeLogLikelihoodLoss"], [21, 2, 1, "", "NonMaxSuppression"], [21, 2, 1, "", "NonZero"], [21, 2, 1, "", "Normalizer"], [21, 2, 1, "", "Not"], [21, 2, 1, "", "OneHot"], [21, 2, 1, "", "OneHotEncoder"], [21, 2, 1, "", "Optional"], [21, 2, 1, "", "OptionalGetElement"], [21, 2, 1, "", "OptionalHasElement"], [21, 2, 1, "", "Or"], [21, 2, 1, "", "PRelu"], [21, 2, 1, "", "Pad"], [21, 2, 1, "", "Pow"], [21, 2, 1, "", "QLinearConv"], [21, 2, 1, "", "QLinearMatMul"], [21, 2, 1, "", "QuantizeLinear"], [21, 2, 1, "", "RNN"], [21, 2, 1, "", "RandomNormal"], [21, 2, 1, "", "RandomNormalLike"], [21, 2, 1, "", "RandomUniform"], [21, 2, 1, "", "RandomUniformLike"], [21, 2, 1, "", "Range"], [21, 2, 1, "", "Reciprocal"], [21, 2, 1, "", "ReduceL1"], [21, 2, 1, "", "ReduceL2"], [21, 2, 1, "", "ReduceLogSum"], [21, 2, 1, "", "ReduceLogSumExp"], [21, 2, 1, "", "ReduceMax"], [21, 2, 1, "", "ReduceMean"], [21, 2, 1, "", "ReduceMin"], [21, 2, 1, "", "ReduceProd"], [21, 2, 1, "", "ReduceSum"], [21, 2, 1, "", "ReduceSumSquare"], [21, 2, 1, "", "RegexFullMatch"], [21, 2, 1, "", "Relu"], [21, 2, 1, "", "Reshape"], [21, 2, 1, "", "Resize"], [21, 2, 1, "", "ReverseSequence"], [21, 2, 1, "", "RoiAlign"], [21, 2, 1, "", "Round"], [21, 2, 1, "", "STFT"], [21, 2, 1, "", "SVMClassifier"], [21, 2, 1, "", "SVMRegressor"], [21, 2, 1, "", "Scaler"], [21, 2, 1, "", "Scan"], [21, 2, 1, "", "Scatter"], [21, 2, 1, "", "ScatterElements"], [21, 2, 1, "", "ScatterND"], [21, 2, 1, "", "Selu"], [21, 2, 1, "", "SequenceAt"], [21, 2, 1, "", "SequenceConstruct"], [21, 2, 1, "", "SequenceEmpty"], [21, 2, 1, "", "SequenceErase"], [21, 2, 1, "", "SequenceInsert"], [21, 2, 1, "", "SequenceLength"], [21, 2, 1, "", "SequenceMap"], [21, 2, 1, "", "Shape"], [21, 2, 1, "", "Shrink"], [21, 2, 1, "", "Sigmoid"], [21, 2, 1, "", "Sign"], [21, 2, 1, "", "Sin"], [21, 2, 1, "", "Sinh"], [21, 2, 1, "", "Size"], [21, 2, 1, "", "Slice"], [21, 2, 1, "", "Softmax"], [21, 2, 1, "", "SoftmaxCrossEntropyLoss"], [21, 2, 1, "", "Softplus"], [21, 2, 1, "", "Softsign"], [21, 2, 1, "", "SpaceToDepth"], [21, 2, 1, "", "Split"], [21, 2, 1, "", "SplitToSequence"], [21, 2, 1, "", "Sqrt"], [21, 2, 1, "", "Squeeze"], [21, 2, 1, "", "StringConcat"], [21, 2, 1, "", "StringNormalizer"], [21, 2, 1, "", "StringSplit"], [21, 2, 1, "", "Sub"], [21, 2, 1, "", "Sum"], [21, 2, 1, "", "Tan"], [21, 2, 1, "", "Tanh"], [21, 2, 1, "", "TfIdfVectorizer"], [21, 2, 1, "", "ThresholdedRelu"], [21, 2, 1, "", "Tile"], [21, 2, 1, "", "TopK"], [21, 2, 1, "", "Transpose"], [21, 2, 1, "", "TreeEnsembleClassifier"], [21, 2, 1, "", "TreeEnsembleRegressor"], [21, 2, 1, "", "Trilu"], [21, 2, 1, "", "Unique"], [21, 2, 1, "", "Unsqueeze"], [21, 2, 1, "", "Upsample"], [21, 2, 1, "", "Where"], [21, 2, 1, "", "Xor"], [21, 2, 1, "", "ZipMap"]], "netspresso.enums.__init__.OriginFrom": [[22, 2, 1, "", "CUSTOM"], [22, 2, 1, "", "NPMS"]], "netspresso.enums.__init__.Policy": [[23, 2, 1, "", "AVERAGE"], [23, 2, 1, "", "SUM"]], "netspresso.enums.__init__.QuantizationMode": [[24, 2, 1, "", "ADVANCED_QUANTIZATION"], [24, 2, 1, "", "AUTOMATIC_QUANTIZATION"], [24, 2, 1, "", "CUSTOM_PRECISION_QUANTIZATION"], [24, 2, 1, "", "RECOMMEND_QUANTIZATION"], [24, 2, 1, "", "UNIFORM_PRECISION_QUANTIZATION"]], "netspresso.enums.__init__.QuantizationPrecision": [[25, 2, 1, "", "FLOAT16"], [25, 2, 1, "", "FLOAT32"], [25, 2, 1, "", "INT8"]], "netspresso.enums.__init__.RecommendationMethod": [[26, 2, 1, "", "SLAMP"], [26, 2, 1, "", "VBMF"]], "netspresso.enums.__init__.SimilarityMetric": [[27, 2, 1, "", "SNR"]], "netspresso.enums.__init__.SoftwareVersion": [[28, 2, 1, "", "JETPACK_4_4_1"], [28, 2, 1, "", "JETPACK_4_6"], [28, 2, 1, "", "JETPACK_5_0_1"], [28, 2, 1, "", "JETPACK_5_0_2"], [28, 2, 1, "", "JETPACK_6_0"]], "netspresso.enums.__init__.Task": [[29, 2, 1, "", "IMAGE_CLASSIFICATION"], [29, 2, 1, "", "OBJECT_DETECTION"], [29, 2, 1, "", "SEMANTIC_SEGMENTATION"]], "netspresso.enums.__init__.TaskStatus": [[30, 2, 1, "", "ERROR"], [30, 2, 1, "", "FINISHED"], [30, 2, 1, "", "IN_PROGRESS"], [30, 2, 1, "", "IN_QUEUE"], [30, 2, 1, "", "TIMEOUT"], [30, 2, 1, "", "USER_CANCEL"]], "netspresso.np_qai.base.NPQAIBase": [[34, 0, 1, "", "get_dataset"], [35, 0, 1, "", "get_datasets"], [37, 0, 1, "", "get_device_attributes"], [38, 0, 1, "", "get_devices"], [39, 0, 1, "", "get_job"], [40, 0, 1, "", "get_job_summaries"], [41, 0, 1, "", "get_model"], [42, 0, 1, "", "get_models"], [36, 0, 1, "", "upload_dataset"], [43, 0, 1, "", "upload_model"]], "netspresso.np_qai.benchmarker.NPQAIBenchmarker": [[44, 0, 1, "", "benchmark_model"], [46, 0, 1, "", "download_benchmark_results"], [47, 0, 1, "", "download_profile"], [48, 0, 1, "", "get_benchmark_task_status"], [49, 0, 1, "", "get_inference_task_status"], [50, 0, 1, "", "inference_model"], [51, 0, 1, "", "update_benchmark_task"]], "netspresso.np_qai.converter.NPQAIConverter": [[52, 0, 1, "", "convert_model"], [54, 0, 1, "", "download_model"], [55, 0, 1, "", "get_convert_task_status"], [56, 0, 1, "", "update_convert_task"]], "netspresso.np_qai.options": [[58, 4, 0, "-", "common"], [59, 4, 0, "-", "compile"], [61, 4, 0, "-", "profile"], [62, 4, 0, "-", "quantize"]], "netspresso.np_qai.options.common": [[58, 1, 1, "", "CommonOptions"], [58, 1, 1, "", "ComputeUnit"]], "netspresso.np_qai.options.common.CommonOptions": [[58, 2, 1, "", "compute_unit"]], "netspresso.np_qai.options.common.ComputeUnit": [[58, 2, 1, "", "ALL"], [58, 2, 1, "", "CPU"], [58, 2, 1, "", "GPU"], [58, 2, 1, "", "NPU"]], "netspresso.np_qai.options.compile": [[59, 1, 1, "", "CompileOptions"], [59, 1, 1, "", "Extension"], [59, 1, 1, "", "Framework"], [59, 1, 1, "", "QuantizeFullType"], [59, 1, 1, "", "QuantizeWeightType"], [59, 1, 1, "", "Runtime"]], "netspresso.np_qai.options.compile.CompileOptions": [[59, 2, 1, "", "force_channel_last_input"], [59, 2, 1, "", "force_channel_last_output"], [59, 2, 1, "", "output_names"], [59, 2, 1, "", "qnn_context_binary_optimization_level"], [59, 2, 1, "", "qnn_context_binary_vtcm"], [59, 2, 1, "", "qnn_graph_name"], [59, 2, 1, "", "quantize_full_type"], [59, 2, 1, "", "quantize_io"], [59, 2, 1, "", "quantize_io_type"], [59, 2, 1, "", "quantize_weight_type"], [59, 2, 1, "", "target_runtime"], [59, 3, 1, "", "to_cli_string"], [59, 2, 1, "", "truncate_64bit_io"], [59, 2, 1, "", "truncate_64bit_tensors"]], "netspresso.np_qai.options.compile.Extension": [[59, 2, 1, "", "AIMET"], [59, 2, 1, "", "H5"], [59, 2, 1, "", "ONNX"], [59, 2, 1, "", "PT"]], "netspresso.np_qai.options.compile.Framework": [[59, 2, 1, "", "AIMET"], [59, 2, 1, "", "COREML"], [59, 2, 1, "", "ONNX"], [59, 2, 1, "", "ONNXRUNTIME"], [59, 2, 1, "", "PYTORCH"], [59, 2, 1, "", "QNN"], [59, 2, 1, "", "TENSORFLOW"], [59, 2, 1, "", "TENSORRT"], [59, 2, 1, "", "TFLITE"]], "netspresso.np_qai.options.compile.QuantizeFullType": [[59, 2, 1, "", "INT16"], [59, 2, 1, "", "INT8"], [59, 2, 1, "", "W4A16"], [59, 2, 1, "", "W4A8"], [59, 2, 1, "", "W8A16"]], "netspresso.np_qai.options.compile.QuantizeWeightType": [[59, 2, 1, "", "FP16"]], "netspresso.np_qai.options.compile.Runtime": [[59, 2, 1, "", "ONNX"], [59, 2, 1, "", "PRECOMPILED_QNN_ONNX"], [59, 2, 1, "", "QNN_CONTEXT_BINARY"], [59, 2, 1, "", "QNN_LIB_AARCH64_ANDROID"], [59, 2, 1, "", "TFLITE"]], "netspresso.np_qai.options.profile": [[61, 1, 1, "", "ContextErrorReportingOptionsLevel"], [61, 1, 1, "", "ContextGpuPerformanceHint"], [61, 1, 1, "", "ContextHtpPerformanceMode"], [61, 1, 1, "", "DefaultGraphGpuPrecision"], [61, 1, 1, "", "DefaultGraphHtpOptimizationType"], [61, 1, 1, "", "DefaultGraphHtpPrecision"], [61, 1, 1, "", "ExecutionMode"], [61, 1, 1, "", "GpuInferencePreference"], [61, 1, 1, "", "GpuInferencePriority"], [61, 1, 1, "", "GraphOptimizationLevel"], [61, 1, 1, "", "InferenceOptions"], [61, 1, 1, "", "NnapiExecutionPreference"], [61, 1, 1, "", "OnnxExecutionProviders"], [61, 1, 1, "", "OnnxOptions"], [61, 1, 1, "", "OnnxQnnHtpPerformanceMode"], [61, 1, 1, "", "OnnxQnnOptions"], [61, 1, 1, "", "Priority"], [61, 1, 1, "", "ProfileCommonOptions"], [61, 1, 1, "", "ProfileOptions"], [61, 1, 1, "", "QnnDspEncoding"], [61, 1, 1, "", "QnnDspPerformanceMode"], [61, 1, 1, "", "QnnGpuPerformanceMode"], [61, 1, 1, "", "QnnGpuPrecision"], [61, 1, 1, "", "QnnGraphPriority"], [61, 1, 1, "", "QnnHtpOptimizationStrategy"], [61, 1, 1, "", "QnnHtpPrecision"], [61, 1, 1, "", "QnnLogLevel"], [61, 1, 1, "", "QnnOptions"], [61, 1, 1, "", "TfliteDelegates"], [61, 1, 1, "", "TfliteGpuv2Options"], [61, 1, 1, "", "TfliteNnapiOptions"], [61, 1, 1, "", "TfliteOptions"], [61, 1, 1, "", "TfliteQnnHtpPerformanceMode"], [61, 1, 1, "", "TfliteQnnOptions"]], "netspresso.np_qai.options.profile.ContextErrorReportingOptionsLevel": [[61, 2, 1, "", "BRIEF"], [61, 2, 1, "", "DETAILED"]], "netspresso.np_qai.options.profile.ContextGpuPerformanceHint": [[61, 2, 1, "", "HIGH"], [61, 2, 1, "", "LOW"], [61, 2, 1, "", "NORMAL"]], "netspresso.np_qai.options.profile.ContextHtpPerformanceMode": [[61, 2, 1, "", "BALANCED"], [61, 2, 1, "", "BURST"], [61, 2, 1, "", "EXTREME_POWER_SAVER"], [61, 2, 1, "", "HIGH_PERFORMANCE"], [61, 2, 1, "", "HIGH_POWER_SAVER"], [61, 2, 1, "", "LOW_BALANCED"], [61, 2, 1, "", "LOW_POWER_SAVER"], [61, 2, 1, "", "POWER_SAVER"], [61, 2, 1, "", "SUSTAINED_HIGH_PERFORMANCE"]], "netspresso.np_qai.options.profile.DefaultGraphGpuPrecision": [[61, 2, 1, "", "FLOAT16"], [61, 2, 1, "", "FLOAT32"], [61, 2, 1, "", "HYBRID"], [61, 2, 1, "", "USER_PROVIDED"]], "netspresso.np_qai.options.profile.DefaultGraphHtpOptimizationType": [[61, 2, 1, "", "FINALIZE_OPTIMIZATION_FLAG"]], "netspresso.np_qai.options.profile.DefaultGraphHtpPrecision": [[61, 2, 1, "", "FLOAT16"]], "netspresso.np_qai.options.profile.ExecutionMode": [[61, 2, 1, "", "PARALLEL"], [61, 2, 1, "", "SEQUENTIAL"]], "netspresso.np_qai.options.profile.GpuInferencePreference": [[61, 2, 1, "", "TFLITE_GPU_INFERENCE_PREFERENCE_BALANCED"], [61, 2, 1, "", "TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER"], [61, 2, 1, "", "TFLITE_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED"]], "netspresso.np_qai.options.profile.GpuInferencePriority": [[61, 2, 1, "", "TFLITE_GPU_INFERENCE_PREFERENCE_BALANCED"], [61, 2, 1, "", "TFLITE_GPU_INFERENCE_PRIORITY_MAX_PRECISION"], [61, 2, 1, "", "TFLITE_GPU_INFERENCE_PRIORITY_MIN_LATENCY"], [61, 2, 1, "", "TFLITE_GPU_INFERENCE_PRIORITY_MIN_MEMORY_USAGE"]], "netspresso.np_qai.options.profile.GraphOptimizationLevel": [[61, 2, 1, "", "DISABLE_ALL"], [61, 2, 1, "", "ENABLE_ALL"], [61, 2, 1, "", "ENABLE_BASIC"], [61, 2, 1, "", "ENABLE_EXTENDED"]], "netspresso.np_qai.options.profile.NnapiExecutionPreference": [[61, 2, 1, "", "K_FAST_SINGLE_ANSWER"], [61, 2, 1, "", "K_LOW_POWER"], [61, 2, 1, "", "K_SUSTAINED_SPEED"]], "netspresso.np_qai.options.profile.OnnxExecutionProviders": [[61, 2, 1, "", "DIRECTML"], [61, 2, 1, "", "QNN"], [61, 2, 1, "", "QNN_GPU"]], "netspresso.np_qai.options.profile.OnnxOptions": [[61, 2, 1, "", "enable_cpu_memory_arena"], [61, 2, 1, "", "enable_memory_pattern"], [61, 2, 1, "", "execution_mode"], [61, 2, 1, "", "graph_optimization_level"], [61, 2, 1, "", "inter_op_num_threads"], [61, 2, 1, "", "intra_op_num_threads"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode": [[61, 2, 1, "", "BALANCED"], [61, 2, 1, "", "BURST"], [61, 2, 1, "", "DEFAULT"], [61, 2, 1, "", "HIGH_PERFORMANCE"], [61, 2, 1, "", "HIGH_POWER_SAVER"], [61, 2, 1, "", "LOW_BALANCED"], [61, 2, 1, "", "LOW_POWER_SAVER"], [61, 2, 1, "", "POWER_SAVER"], [61, 2, 1, "", "SUSTAINED_HIGH_PERFORMANCE"]], "netspresso.np_qai.options.profile.OnnxQnnOptions": [[61, 2, 1, "", "qnn_enable_htp_fp16_precision"], [61, 2, 1, "", "qnn_htp_graph_optimization_mode"], [61, 2, 1, "", "qnn_htp_performance_mode"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.profile.Priority": [[61, 2, 1, "", "HIGH"], [61, 2, 1, "", "LOW"], [61, 2, 1, "", "NORMAL"], [61, 2, 1, "", "NORMAL_HIGH"]], "netspresso.np_qai.options.profile.ProfileCommonOptions": [[61, 2, 1, "", "dequantize_outputs"], [61, 3, 1, "", "handle_common_options"], [61, 3, 1, "", "handle_onnx_options"], [61, 3, 1, "", "handle_qnn_options"], [61, 3, 1, "", "handle_tflite_options"], [61, 2, 1, "", "max_profiler_iterations"], [61, 2, 1, "", "max_profiler_time"], [61, 2, 1, "", "onnx_execution_providers"], [61, 2, 1, "", "onnx_options"], [61, 2, 1, "", "qnn_options"], [61, 2, 1, "", "tflite_delegates"], [61, 2, 1, "", "tflite_options"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.profile.QnnDspEncoding": [[61, 2, 1, "", "K_DSP_DYNAMIC"], [61, 2, 1, "", "K_DSP_STATIC"]], "netspresso.np_qai.options.profile.QnnDspPerformanceMode": [[61, 2, 1, "", "K_DPS_SUSTAINED_HIGH_PERFORMANCE"], [61, 2, 1, "", "K_DSP_BALANCED"], [61, 2, 1, "", "K_DSP_BURST"], [61, 2, 1, "", "K_DSP_HIGH_PERFORMANCE"], [61, 2, 1, "", "K_DSP_HIGH_POWER_SAVER"], [61, 2, 1, "", "K_DSP_LOW_BALANCED"], [61, 2, 1, "", "K_DSP_LOW_POWER_SAVER"], [61, 2, 1, "", "K_DSP_POWER_SAVER"]], "netspresso.np_qai.options.profile.QnnGpuPerformanceMode": [[61, 2, 1, "", "K_GPU_DEFAULT"], [61, 2, 1, "", "K_GPU_HIGH"], [61, 2, 1, "", "K_GPU_LOW"], [61, 2, 1, "", "K_GPU_NORMAL"]], "netspresso.np_qai.options.profile.QnnGpuPrecision": [[61, 2, 1, "", "K_GPU_FP16"], [61, 2, 1, "", "K_GPU_FP32"], [61, 2, 1, "", "K_GPU_HYBRID"], [61, 2, 1, "", "K_GPU_USER_PROVIDED"]], "netspresso.np_qai.options.profile.QnnGraphPriority": [[61, 2, 1, "", "K_QNN_PRIORITY_DEFAULT"], [61, 2, 1, "", "K_QNN_PRIORITY_HIGH"], [61, 2, 1, "", "K_QNN_PRIORITY_LOW"], [61, 2, 1, "", "K_QNN_PRIORITY_NORMAL"], [61, 2, 1, "", "K_QNN_PRIORITY_NORMAL_HIGH"], [61, 2, 1, "", "K_QNN_PRIORITY_UNDEFINED"]], "netspresso.np_qai.options.profile.QnnHtpOptimizationStrategy": [[61, 2, 1, "", "K_HTP_OPTIMIZE_FOR_INFERENCE"], [61, 2, 1, "", "K_HTP_OPTIMIZE_FOR_PREPARE"]], "netspresso.np_qai.options.profile.QnnHtpPrecision": [[61, 2, 1, "", "K_HTP_FP16"], [61, 2, 1, "", "K_HTP_QUANTIZED"]], "netspresso.np_qai.options.profile.QnnLogLevel": [[61, 2, 1, "", "K_LOG_LEVEL_DEBUG"], [61, 2, 1, "", "K_LOG_LEVEL_ERROR"], [61, 2, 1, "", "K_LOG_LEVEL_INFO"], [61, 2, 1, "", "K_LOG_LEVEL_VERBOSE"], [61, 2, 1, "", "K_LOG_LEVEL_WARN"], [61, 2, 1, "", "K_LOG_OFF"]], "netspresso.np_qai.options.profile.QnnOptions": [[61, 2, 1, "", "context_async_execution_queue_depth_numeric"], [61, 2, 1, "", "context_enable_graphs"], [61, 2, 1, "", "context_error_reporting_options_level"], [61, 2, 1, "", "context_error_reporting_options_storage_limit"], [61, 2, 1, "", "context_gpu_performance_hint"], [61, 2, 1, "", "context_gpu_use_gl_buffers"], [61, 2, 1, "", "context_htp_performance_mode"], [61, 2, 1, "", "context_memory_limit_hint"], [61, 2, 1, "", "context_priority"], [61, 2, 1, "", "default_graph_gpu_disable_memory_optimizations"], [61, 2, 1, "", "default_graph_gpu_disable_node_optimizations"], [61, 2, 1, "", "default_graph_gpu_disable_queue_recording"], [61, 2, 1, "", "default_graph_gpu_precision"], [61, 2, 1, "", "default_graph_htp_disable_fold_relu_activation_into_conv"], [61, 2, 1, "", "default_graph_htp_disable_short_depth_conv_on_hmx"], [61, 2, 1, "", "default_graph_htp_num_hvx_threads"], [61, 2, 1, "", "default_graph_htp_optimization_type"], [61, 2, 1, "", "default_graph_htp_optimization_value"], [61, 2, 1, "", "default_graph_htp_precision"], [61, 2, 1, "", "default_graph_htp_vtcm_size"], [61, 2, 1, "", "default_graph_priority"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.profile.TfliteDelegates": [[61, 2, 1, "", "GPU"], [61, 2, 1, "", "NNAPI"], [61, 2, 1, "", "NNAPI_GPU"], [61, 2, 1, "", "QNN"], [61, 2, 1, "", "QNN_GPU"], [61, 2, 1, "", "XNNPACK"]], "netspresso.np_qai.options.profile.TfliteGpuv2Options": [[61, 2, 1, "", "gpu_inference_preference"], [61, 2, 1, "", "gpu_inference_priority1"], [61, 2, 1, "", "gpu_inference_priority2"], [61, 2, 1, "", "gpu_inference_priority3"], [61, 2, 1, "", "gpu_max_delegated_partitions"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.profile.TfliteNnapiOptions": [[61, 2, 1, "", "nnapi_allow_fp16"], [61, 2, 1, "", "nnapi_execution_preference"], [61, 2, 1, "", "nnapi_max_number_delegated_partitions"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.profile.TfliteOptions": [[61, 2, 1, "", "allow_fp32_as_fp16"], [61, 2, 1, "", "enable_fallback"], [61, 2, 1, "", "force_opengl"], [61, 2, 1, "", "invoke_interpreter_on_cold_load"], [61, 2, 1, "", "number_of_threads"], [61, 2, 1, "", "release_dynamic_tensors"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode": [[61, 2, 1, "", "K_HTP_BALANCED"], [61, 2, 1, "", "K_HTP_BURST"], [61, 2, 1, "", "K_HTP_HIGH_PERFORMANCE"], [61, 2, 1, "", "K_HTP_HIGH_POWER_SAVER"], [61, 2, 1, "", "K_HTP_LOW_BALANCED"], [61, 2, 1, "", "K_HTP_LOW_POWER_SAVER"], [61, 2, 1, "", "K_HTP_POWER_SAVER"], [61, 2, 1, "", "K_HTP_SUSTAINED_HIGH_PERFORMANCE"]], "netspresso.np_qai.options.profile.TfliteQnnOptions": [[61, 2, 1, "", "qnn_dsp_encoding"], [61, 2, 1, "", "qnn_dsp_performance_mode"], [61, 2, 1, "", "qnn_gpu_performance_mode"], [61, 2, 1, "", "qnn_gpu_precision"], [61, 2, 1, "", "qnn_graph_priority"], [61, 2, 1, "", "qnn_htp_num_hvx_threads"], [61, 2, 1, "", "qnn_htp_optimization_strategy"], [61, 2, 1, "", "qnn_htp_performance_mode"], [61, 2, 1, "", "qnn_htp_precision"], [61, 2, 1, "", "qnn_htp_use_conv_hmx"], [61, 2, 1, "", "qnn_htp_use_fold_relu"], [61, 2, 1, "", "qnn_htp_vtcm_size"], [61, 2, 1, "", "qnn_log_level"], [61, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.quantize": [[62, 1, 1, "", "QuantizeOptions"], [62, 1, 1, "", "QuantizePrecision"], [62, 1, 1, "", "RangeScheme"]], "netspresso.np_qai.options.quantize.QuantizeOptions": [[62, 2, 1, "", "range_scheme"], [62, 3, 1, "", "to_cli_string"]], "netspresso.np_qai.options.quantize.QuantizePrecision": [[62, 2, 1, "", "INT16"], [62, 2, 1, "", "INT4"], [62, 2, 1, "", "INT8"]], "netspresso.np_qai.options.quantize.RangeScheme": [[62, 2, 1, "", "AUTO"], [62, 2, 1, "", "MIN_MAX"], [62, 2, 1, "", "MSE_MINIMIZER"]], "netspresso.np_qai.quantizer.NPQAIQuantizer": [[63, 0, 1, "", "download_model"], [64, 0, 1, "", "get_quantize_task_status"], [65, 0, 1, "", "quantize_model"], [67, 0, 1, "", "update_quantize_task"]], "netspresso.quantizer.__init__.Quantizer": [[68, 0, 1, "", "automatic_quantization"], [69, 0, 1, "", "custom_precision_quantization_by_layer_name"], [70, 0, 1, "", "custom_precision_quantization_by_operator_type"], [71, 0, 1, "", "get_recommendation_precision"], [72, 0, 1, "", "uniform_precision_quantization"]], "netspresso.trainer.trainer": [[74, 1, 1, "", "Trainer"]], "netspresso.trainer.trainer.Trainer": [[74, 3, 1, "", "set_augmentation_config"], [74, 3, 1, "", "set_dataset_config"], [74, 3, 1, "", "set_environment_config"], [74, 3, 1, "", "set_fx_model"], [74, 3, 1, "", "set_logging_config"], [74, 3, 1, "", "set_model_config"], [74, 3, 1, "", "set_training_config"], [74, 3, 1, "", "train"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:module"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "module", "Python module"]}, "titleterms": {"api": 0, "descript": 0, "benchmark": [1, 2, 44, 45, 46, 48, 51], "model": [1, 5, 11, 33, 41, 42, 43, 44, 50, 52, 54, 63, 65], "exampl": [1, 5, 7, 8, 9, 11, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 52, 65, 68, 69, 70, 71, 72, 74], "advanc": 3, "compress": [3, 4, 5, 7, 8, 9, 10, 13], "method": [4, 5, 7, 13, 26], "content": [4, 6, 76], "structur": 4, "prune": [4, 6], "criteria": 4, "neuron": 4, "level": 4, "snp": 4, "l2": 4, "norm": [4, 6], "gm": 4, "nuclear": 4, "channel": [4, 6], "index": 4, "filter": 4, "decomposit": 4, "tucker": 4, "singular": 4, "valu": [4, 5], "cp": 4, "manual": 5, "upload": [5, 36, 43], "detail": [5, 7, 8, 9], "paramet": [5, 7, 8], "framework": [5, 17], "avail": [5, 7], "input": 5, "shape": 5, "select": 5, "option": [5, 6, 7, 58, 59, 60, 61, 62], "return": [5, 9], "output": [5, 9], "set": 5, "param": 5, "layer": [5, 6, 69], "full": 5, "polici": [6, 18, 23], "sum": 6, "averag": 6, "standard": 6, "score": 6, "tss": 6, "total": 6, "scale": 6, "normal": 6, "linear": 6, "softmax": 6, "none": 6, "group": [6, 18], "count": 6, "reshap": 6, "axi": 6, "step": 6, "oper": [6, 70], "round": 6, "up": 6, "down": 6, "recommend": [7, 26, 71], "ratio": [7, 8], "automat": [8, 68], "get": [9, 34, 35, 37, 38, 39, 40, 41, 42, 48, 49, 55, 64], "inform": 9, "compressor": 10, "convert": [11, 12, 52, 53, 55, 56], "data": 14, "type": [14, 19, 70], "devic": [15, 33, 37, 38], "name": [15, 69], "extens": 16, "hardwar": 19, "layernorm": 20, "onnxoper": 21, "origin": 22, "from": 22, "quantizationmod": 24, "quantizationprecis": 25, "similaritymetr": 27, "softwar": 28, "version": 28, "task": [29, 30, 48, 49, 51, 55, 56, 64, 67], "statu": [30, 48, 49, 55, 64], "enum": 31, "quantiz": [62, 64, 65, 66, 67, 68, 69, 70, 72, 73], "custom": [69, 70], "precis": [69, 70, 71], "plain": 72, "train": [74, 75], "retrain": 74, "trainer": 75, "welcom": 76, "netspresso": [32, 57, 76], "tabl": 76, "contact": 76, "instal": 77, "prerequisit": 77, "pypi": 77, "stabl": 77, "github": 77, "docker": 77, "compos": 77, "imag": 77, "build": 77, "qai": 57, "download": [46, 47, 54, 63], "result": 46, "profil": [47, 61], "infer": [49, 50], "updat": [51, 56, 67], "common": 58, "compil": 59, "creat": 65, "calibr": 65, "dataset": [33, 34, 35, 36, 65], "base": 33, "function": [], "attribut": 37, "job": [33, 39, 40], "summari": 40}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"Welcome to NetsPresso!": [[76, "welcome-to-netspresso"]], "Table of Contents:": [[76, null]], "Contact": [[76, "contact"]], "Installation": [[77, "installation"]], "Prerequisites": [[77, "prerequisites"]], "Install with PyPI (stable)": [[77, "install-with-pypi-stable"]], "Install with GitHub": [[77, "install-with-github"]], "Install with Docker": [[77, "install-with-docker"]], "Docker with docker-compose": [[77, "docker-with-docker-compose"]], "Docker image build": [[77, "docker-image-build"]], "Benchmarker": [[2, "benchmarker"], [45, "benchmarker"]], "Benchmark": [[2, "benchmark"]], "Advanced Compression": [[3, "advanced-compression"]], "Compression Method": [[4, "compression-method"], [13, "compression-method"], [5, "compression-method"], [7, "compression-method"]], "Contents": [[4, "contents"], [6, "contents"]], "Structured Pruning": [[4, "structured-pruning"]], "Pruning by Criteria": [[4, "pruning-by-criteria"]], "Structured Neuron-level Pruning (SNP)": [[4, "structured-neuron-level-pruning-snp"]], "L2 Norm Pruning": [[4, "l2-norm-pruning"]], "GM Pruning": [[4, "gm-pruning"]], "Nuclear Norm Pruning": [[4, "nuclear-norm-pruning"]], "Pruning by Channel Index": [[4, "pruning-by-channel-index"]], "Filter Decomposition": [[4, "filter-decomposition"]], "Tucker Decomposition": [[4, "tucker-decomposition"]], "Singular Value Decomposition": [[4, "singular-value-decomposition"]], "CP Decomposition": [[4, "cp-decomposition"]], "Pruning Options": [[6, "pruning-options"]], "Policy": [[6, "policy"], [23, "policy"]], "Sum": [[6, "sum"], [6, "id1"]], "Average": [[6, "average"], [6, "id2"]], "Layer Norm": [[6, "layer-norm"]], "Standard Score": [[6, "standard-score"]], "TSS Norm (Total sum scaling normalization)": [[6, "tss-norm-total-sum-scaling-normalization"]], "Linear Scaling": [[6, "linear-scaling"]], "Softmax Norm": [[6, "softmax-norm"]], "None": [[6, "none"], [6, "id3"], [6, "id4"]], "Group Policy": [[6, "group-policy"], [18, "group-policy"]], "Count": [[6, "count"]], "Reshape Channel Axis": [[6, "reshape-channel-axis"]], "Step operator": [[6, "step-operator"]], "Round": [[6, "round"]], "Round Up": [[6, "round-up"]], "Round Down": [[6, "round-down"]], "Compressor": [[10, "compressor"]], "Compress": [[10, "compress"]], "Converter": [[12, "converter"], [53, "converter"]], "Convert": [[12, "convert"]], "Data Type": [[14, "data-type"]], "Device Name": [[15, "device-name"]], "Extension": [[16, "extension"]], "Framework": [[17, "framework"], [5, "framework"]], "Hardware Type": [[19, "hardware-type"]], "LayerNorm": [[20, "layernorm"]], "OnnxOperator": [[21, "onnxoperator"]], "Origin From": [[22, "origin-from"]], "QuantizationMode": [[24, "quantizationmode"]], "QuantizationPrecision": [[25, "quantizationprecision"]], "Recommendation Method": [[26, "recommendation-method"], [7, "recommendation-method"]], "SimilarityMetric": [[27, "similaritymetric"]], "Software Version": [[28, "software-version"]], "Task": [[29, "task"]], "Task Status": [[30, "task-status"]], "Enums": [[31, "enums"]], "Quantizer": [[73, "quantizer"], [66, "quantizer"]], "Quantize": [[73, "quantize"]], "Trainer": [[75, "trainer"]], "Train": [[75, "train"], [74, "train"], [74, "id1"]], "API Description": [[0, "api-description"]], "Benchmark Model": [[1, "benchmark-model"], [44, "benchmark-model"]], "Example": [[1, "example"], [5, "example"], [5, "id1"], [5, "id3"], [5, "id4"], [5, "id5"], [5, "id7"], [5, "id9"], [7, "example"], [7, "id1"], [7, "id2"], [7, "id3"], [8, "example"], [9, "example"], [11, "example"], [34, "example"], [35, "example"], [36, "example"], [37, "example"], [38, "example"], [39, "example"], [40, "example"], [41, "example"], [42, "example"], [43, "example"], [44, "example"], [52, "example"], [65, "example"], [68, "example"], [69, "example"], [70, "example"], [71, "example"], [72, "example"], [74, "example"]], "Manual Compression": [[5, "manual-compression"]], "Upload Model": [[5, "upload-model"], [43, "upload-model"]], "Details of Parameters": [[5, "details-of-parameters"], [5, "id2"], [5, "id6"], [7, "details-of-parameters"], [8, "details-of-parameters"]], "Available Framework": [[5, "available-framework"]], "Input Shapes": [[5, "input-shapes"]], "Select Compression Method": [[5, "select-compression-method"]], "Available Compression Method": [[5, "available-compression-method"], [7, "available-compression-method"]], "Options": [[5, "options"], [7, "options"], [60, "options"]], "Details of Returns": [[5, "details-of-returns"], [9, "details-of-returns"]], "Output": [[5, "output"], [5, "id8"], [9, "output"]], "Set Compression Params": [[5, "set-compression-params"]], "Values of available layer": [[5, "values-of-available-layer"]], "Compress Model": [[5, "compress-model"]], "Full Example": [[5, "full-example"]], "Recommendation Compression": [[7, "recommendation-compression"]], "Available Recommendation Method": [[7, "available-recommendation-method"]], "Recommendation Ratio": [[7, "recommendation-ratio"]], "Automatic Compression": [[8, "automatic-compression"]], "Compression Ratio": [[8, "compression-ratio"]], "Get Compression Information": [[9, "get-compression-information"]], "Convert Model": [[11, "convert-model"], [52, "convert-model"]], "NetsPresso": [[32, "netspresso"]], "Base": [[33, "base"]], "Dataset": [[33, "dataset"]], "Model": [[33, "model"]], "Device": [[33, "device"]], "Job": [[33, "job"]], "Get Dataset": [[34, "get-dataset"]], "Get Datasets": [[35, "get-datasets"]], "Upload Dataset": [[36, "upload-dataset"]], "Get Device Attributes": [[37, "get-device-attributes"]], "Get Devices": [[38, "get-devices"]], "Get Job": [[39, "get-job"]], "Get Job Summaries": [[40, "get-job-summaries"]], "Get Model": [[41, "get-model"]], "Get Models": [[42, "get-models"]], "Download Benchmark Results": [[46, "download-benchmark-results"]], "Download Profile": [[47, "download-profile"]], "Get Benchmark Task Status": [[48, "get-benchmark-task-status"]], "Get Inference Task Status": [[49, "get-inference-task-status"]], "Inference Model": [[50, "inference-model"]], "Update Benchmark Task": [[51, "update-benchmark-task"]], "Download Model": [[54, "download-model"], [63, "download-model"]], "Get Convert Task Status": [[55, "get-convert-task-status"]], "Update Convert Task": [[56, "update-convert-task"]], "NetsPresso QAI": [[57, "netspresso-qai"]], "Common Options": [[58, "module-netspresso.np_qai.options.common"]], "Compile Options": [[59, "module-netspresso.np_qai.options.compile"]], "Profile Options": [[61, "module-netspresso.np_qai.options.profile"]], "Quantize Options": [[62, "module-netspresso.np_qai.options.quantize"]], "Get Quantize Task Status": [[64, "get-quantize-task-status"]], "Quantize Model": [[65, "quantize-model"]], "Create Calibration Datasets": [[65, "create-calibration-datasets"]], "Update Quantize Task": [[67, "update-quantize-task"]], "Automatic Quantization": [[68, "automatic-quantization"]], "Custom Precision Quantization by Layer Name": [[69, "custom-precision-quantization-by-layer-name"]], "Custom Precision Quantization by Operator Type": [[70, "custom-precision-quantization-by-operator-type"]], "Recommendation precision": [[71, "recommendation-precision"]], "Plain Quantization": [[72, "plain-quantization"]], "Retrain": [[74, "retrain"]]}, "indexentries": {"benchmark_model() (in module netspresso.benchmarker.__init__.benchmarkerv2)": [[1, "netspresso.benchmarker.__init__.BenchmarkerV2.benchmark_model"]], "compress_model() (in module netspresso.compressor.__init__.compressorv2)": [[5, "netspresso.compressor.__init__.CompressorV2.compress_model"]], "select_compression_method() (in module netspresso.compressor.__init__.compressorv2)": [[5, "netspresso.compressor.__init__.CompressorV2.select_compression_method"]], "upload_model() (in module netspresso.compressor.__init__.compressorv2)": [[5, "netspresso.compressor.__init__.CompressorV2.upload_model"]], "recommendation_compression() (in module netspresso.compressor.__init__.compressorv2)": [[7, "netspresso.compressor.__init__.CompressorV2.recommendation_compression"]], "automatic_compression() (in module netspresso.compressor.__init__.compressorv2)": [[8, "netspresso.compressor.__init__.CompressorV2.automatic_compression"]], "get_compression() (in module netspresso.compressor.__init__.compressorv2)": [[9, "netspresso.compressor.__init__.CompressorV2.get_compression"]], "convert_model() (in module netspresso.converter.__init__.converterv2)": [[11, "netspresso.converter.__init__.ConverterV2.convert_model"]], "get_dataset() (in module netspresso.np_qai.base.npqaibase)": [[34, "netspresso.np_qai.base.NPQAIBase.get_dataset"]], "get_datasets() (in module netspresso.np_qai.base.npqaibase)": [[35, "netspresso.np_qai.base.NPQAIBase.get_datasets"]], "upload_dataset() (in module netspresso.np_qai.base.npqaibase)": [[36, "netspresso.np_qai.base.NPQAIBase.upload_dataset"]], "get_device_attributes() (in module netspresso.np_qai.base.npqaibase)": [[37, "netspresso.np_qai.base.NPQAIBase.get_device_attributes"]], "get_devices() (in module netspresso.np_qai.base.npqaibase)": [[38, "netspresso.np_qai.base.NPQAIBase.get_devices"]], "get_job() (in module netspresso.np_qai.base.npqaibase)": [[39, "netspresso.np_qai.base.NPQAIBase.get_job"]], "get_job_summaries() (in module netspresso.np_qai.base.npqaibase)": [[40, "netspresso.np_qai.base.NPQAIBase.get_job_summaries"]], "get_model() (in module netspresso.np_qai.base.npqaibase)": [[41, "netspresso.np_qai.base.NPQAIBase.get_model"]], "get_models() (in module netspresso.np_qai.base.npqaibase)": [[42, "netspresso.np_qai.base.NPQAIBase.get_models"]], "upload_model() (in module netspresso.np_qai.base.npqaibase)": [[43, "netspresso.np_qai.base.NPQAIBase.upload_model"]], "benchmark_model() (in module netspresso.np_qai.benchmarker.npqaibenchmarker)": [[44, "netspresso.np_qai.benchmarker.NPQAIBenchmarker.benchmark_model"]], "download_benchmark_results() (in module netspresso.np_qai.benchmarker.npqaibenchmarker)": [[46, "netspresso.np_qai.benchmarker.NPQAIBenchmarker.download_benchmark_results"]], "download_profile() (in module netspresso.np_qai.benchmarker.npqaibenchmarker)": [[47, "netspresso.np_qai.benchmarker.NPQAIBenchmarker.download_profile"]], "get_benchmark_task_status() (in module netspresso.np_qai.benchmarker.npqaibenchmarker)": [[48, "netspresso.np_qai.benchmarker.NPQAIBenchmarker.get_benchmark_task_status"]], "get_inference_task_status() (in module netspresso.np_qai.benchmarker.npqaibenchmarker)": [[49, "netspresso.np_qai.benchmarker.NPQAIBenchmarker.get_inference_task_status"]], "inference_model() (in module netspresso.np_qai.benchmarker.npqaibenchmarker)": [[50, "netspresso.np_qai.benchmarker.NPQAIBenchmarker.inference_model"]], "update_benchmark_task() (in module netspresso.np_qai.benchmarker.npqaibenchmarker)": [[51, "netspresso.np_qai.benchmarker.NPQAIBenchmarker.update_benchmark_task"]], "convert_model() (in module netspresso.np_qai.converter.npqaiconverter)": [[52, "netspresso.np_qai.converter.NPQAIConverter.convert_model"]], "download_model() (in module netspresso.np_qai.converter.npqaiconverter)": [[54, "netspresso.np_qai.converter.NPQAIConverter.download_model"]], "get_convert_task_status() (in module netspresso.np_qai.converter.npqaiconverter)": [[55, "netspresso.np_qai.converter.NPQAIConverter.get_convert_task_status"]], "update_convert_task() (in module netspresso.np_qai.converter.npqaiconverter)": [[56, "netspresso.np_qai.converter.NPQAIConverter.update_convert_task"]], "all (computeunit attribute)": [[58, "netspresso.np_qai.options.common.ComputeUnit.ALL"]], "cpu (computeunit attribute)": [[58, "netspresso.np_qai.options.common.ComputeUnit.CPU"]], "commonoptions (class in netspresso.np_qai.options.common)": [[58, "netspresso.np_qai.options.common.CommonOptions"]], "computeunit (class in netspresso.np_qai.options.common)": [[58, "netspresso.np_qai.options.common.ComputeUnit"]], "gpu (computeunit attribute)": [[58, "netspresso.np_qai.options.common.ComputeUnit.GPU"]], "npu (computeunit attribute)": [[58, "netspresso.np_qai.options.common.ComputeUnit.NPU"]], "compute_unit (commonoptions attribute)": [[58, "netspresso.np_qai.options.common.CommonOptions.compute_unit"]], "module": [[58, "module-netspresso.np_qai.options.common"], [59, "module-netspresso.np_qai.options.compile"], [61, "module-netspresso.np_qai.options.profile"], [62, "module-netspresso.np_qai.options.quantize"]], "netspresso.np_qai.options.common": [[58, "module-netspresso.np_qai.options.common"]], "aimet (extension attribute)": [[59, "netspresso.np_qai.options.compile.Extension.AIMET"]], "aimet (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.AIMET"]], "coreml (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.COREML"]], "compileoptions (class in netspresso.np_qai.options.compile)": [[59, "netspresso.np_qai.options.compile.CompileOptions"]], "extension (class in netspresso.np_qai.options.compile)": [[59, "netspresso.np_qai.options.compile.Extension"]], "fp16 (quantizeweighttype attribute)": [[59, "netspresso.np_qai.options.compile.QuantizeWeightType.FP16"]], "framework (class in netspresso.np_qai.options.compile)": [[59, "netspresso.np_qai.options.compile.Framework"]], "h5 (extension attribute)": [[59, "netspresso.np_qai.options.compile.Extension.H5"]], "int16 (quantizefulltype attribute)": [[59, "netspresso.np_qai.options.compile.QuantizeFullType.INT16"]], "int8 (quantizefulltype attribute)": [[59, "netspresso.np_qai.options.compile.QuantizeFullType.INT8"]], "onnx (extension attribute)": [[59, "netspresso.np_qai.options.compile.Extension.ONNX"]], "onnx (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.ONNX"]], "onnx (runtime attribute)": [[59, "netspresso.np_qai.options.compile.Runtime.ONNX"]], "onnxruntime (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.ONNXRUNTIME"]], "precompiled_qnn_onnx (runtime attribute)": [[59, "netspresso.np_qai.options.compile.Runtime.PRECOMPILED_QNN_ONNX"]], "pt (extension attribute)": [[59, "netspresso.np_qai.options.compile.Extension.PT"]], "pytorch (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.PYTORCH"]], "qnn (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.QNN"]], "qnn_context_binary (runtime attribute)": [[59, "netspresso.np_qai.options.compile.Runtime.QNN_CONTEXT_BINARY"]], "qnn_lib_aarch64_android (runtime attribute)": [[59, "netspresso.np_qai.options.compile.Runtime.QNN_LIB_AARCH64_ANDROID"]], "quantizefulltype (class in netspresso.np_qai.options.compile)": [[59, "netspresso.np_qai.options.compile.QuantizeFullType"]], "quantizeweighttype (class in netspresso.np_qai.options.compile)": [[59, "netspresso.np_qai.options.compile.QuantizeWeightType"]], "runtime (class in netspresso.np_qai.options.compile)": [[59, "netspresso.np_qai.options.compile.Runtime"]], "tensorflow (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.TENSORFLOW"]], "tensorrt (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.TENSORRT"]], "tflite (framework attribute)": [[59, "netspresso.np_qai.options.compile.Framework.TFLITE"]], "tflite (runtime attribute)": [[59, "netspresso.np_qai.options.compile.Runtime.TFLITE"]], "w4a16 (quantizefulltype attribute)": [[59, "netspresso.np_qai.options.compile.QuantizeFullType.W4A16"]], "w4a8 (quantizefulltype attribute)": [[59, "netspresso.np_qai.options.compile.QuantizeFullType.W4A8"]], "w8a16 (quantizefulltype attribute)": [[59, "netspresso.np_qai.options.compile.QuantizeFullType.W8A16"]], "force_channel_last_input (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.force_channel_last_input"]], "force_channel_last_output (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.force_channel_last_output"]], "netspresso.np_qai.options.compile": [[59, "module-netspresso.np_qai.options.compile"]], "output_names (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.output_names"]], "qnn_context_binary_optimization_level (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.qnn_context_binary_optimization_level"]], "qnn_context_binary_vtcm (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.qnn_context_binary_vtcm"]], "qnn_graph_name (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.qnn_graph_name"]], "quantize_full_type (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.quantize_full_type"]], "quantize_io (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.quantize_io"]], "quantize_io_type (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.quantize_io_type"]], "quantize_weight_type (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.quantize_weight_type"]], "target_runtime (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.target_runtime"]], "to_cli_string() (compileoptions method)": [[59, "netspresso.np_qai.options.compile.CompileOptions.to_cli_string"]], "truncate_64bit_io (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.truncate_64bit_io"]], "truncate_64bit_tensors (compileoptions attribute)": [[59, "netspresso.np_qai.options.compile.CompileOptions.truncate_64bit_tensors"]], "balanced (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.BALANCED"]], "balanced (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.BALANCED"]], "brief (contexterrorreportingoptionslevel attribute)": [[61, "netspresso.np_qai.options.profile.ContextErrorReportingOptionsLevel.BRIEF"]], "burst (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.BURST"]], "burst (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.BURST"]], "contexterrorreportingoptionslevel (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.ContextErrorReportingOptionsLevel"]], "contextgpuperformancehint (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.ContextGpuPerformanceHint"]], "contexthtpperformancemode (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode"]], "default (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.DEFAULT"]], "detailed (contexterrorreportingoptionslevel attribute)": [[61, "netspresso.np_qai.options.profile.ContextErrorReportingOptionsLevel.DETAILED"]], "directml (onnxexecutionproviders attribute)": [[61, "netspresso.np_qai.options.profile.OnnxExecutionProviders.DIRECTML"]], "disable_all (graphoptimizationlevel attribute)": [[61, "netspresso.np_qai.options.profile.GraphOptimizationLevel.DISABLE_ALL"]], "defaultgraphgpuprecision (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.DefaultGraphGpuPrecision"]], "defaultgraphhtpoptimizationtype (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.DefaultGraphHtpOptimizationType"]], "defaultgraphhtpprecision (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.DefaultGraphHtpPrecision"]], "enable_all (graphoptimizationlevel attribute)": [[61, "netspresso.np_qai.options.profile.GraphOptimizationLevel.ENABLE_ALL"]], "enable_basic (graphoptimizationlevel attribute)": [[61, "netspresso.np_qai.options.profile.GraphOptimizationLevel.ENABLE_BASIC"]], "enable_extended (graphoptimizationlevel attribute)": [[61, "netspresso.np_qai.options.profile.GraphOptimizationLevel.ENABLE_EXTENDED"]], "extreme_power_saver (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.EXTREME_POWER_SAVER"]], "executionmode (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.ExecutionMode"]], "finalize_optimization_flag (defaultgraphhtpoptimizationtype attribute)": [[61, "netspresso.np_qai.options.profile.DefaultGraphHtpOptimizationType.FINALIZE_OPTIMIZATION_FLAG"]], "float16 (defaultgraphgpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.DefaultGraphGpuPrecision.FLOAT16"]], "float16 (defaultgraphhtpprecision attribute)": [[61, "netspresso.np_qai.options.profile.DefaultGraphHtpPrecision.FLOAT16"]], "float32 (defaultgraphgpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.DefaultGraphGpuPrecision.FLOAT32"]], "gpu (tflitedelegates attribute)": [[61, "netspresso.np_qai.options.profile.TfliteDelegates.GPU"]], "gpuinferencepreference (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.GpuInferencePreference"]], "gpuinferencepriority (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.GpuInferencePriority"]], "graphoptimizationlevel (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.GraphOptimizationLevel"]], "high (contextgpuperformancehint attribute)": [[61, "netspresso.np_qai.options.profile.ContextGpuPerformanceHint.HIGH"]], "high (priority attribute)": [[61, "netspresso.np_qai.options.profile.Priority.HIGH"]], "high_performance (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.HIGH_PERFORMANCE"]], "high_performance (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.HIGH_PERFORMANCE"]], "high_power_saver (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.HIGH_POWER_SAVER"]], "high_power_saver (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.HIGH_POWER_SAVER"]], "hybrid (defaultgraphgpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.DefaultGraphGpuPrecision.HYBRID"]], "inferenceoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.InferenceOptions"]], "k_dps_sustained_high_performance (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DPS_SUSTAINED_HIGH_PERFORMANCE"]], "k_dsp_balanced (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DSP_BALANCED"]], "k_dsp_burst (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DSP_BURST"]], "k_dsp_dynamic (qnndspencoding attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspEncoding.K_DSP_DYNAMIC"]], "k_dsp_high_performance (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DSP_HIGH_PERFORMANCE"]], "k_dsp_high_power_saver (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DSP_HIGH_POWER_SAVER"]], "k_dsp_low_balanced (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DSP_LOW_BALANCED"]], "k_dsp_low_power_saver (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DSP_LOW_POWER_SAVER"]], "k_dsp_power_saver (qnndspperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode.K_DSP_POWER_SAVER"]], "k_dsp_static (qnndspencoding attribute)": [[61, "netspresso.np_qai.options.profile.QnnDspEncoding.K_DSP_STATIC"]], "k_fast_single_answer (nnapiexecutionpreference attribute)": [[61, "netspresso.np_qai.options.profile.NnapiExecutionPreference.K_FAST_SINGLE_ANSWER"]], "k_gpu_default (qnngpuperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPerformanceMode.K_GPU_DEFAULT"]], "k_gpu_fp16 (qnngpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPrecision.K_GPU_FP16"]], "k_gpu_fp32 (qnngpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPrecision.K_GPU_FP32"]], "k_gpu_high (qnngpuperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPerformanceMode.K_GPU_HIGH"]], "k_gpu_hybrid (qnngpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPrecision.K_GPU_HYBRID"]], "k_gpu_low (qnngpuperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPerformanceMode.K_GPU_LOW"]], "k_gpu_normal (qnngpuperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPerformanceMode.K_GPU_NORMAL"]], "k_gpu_user_provided (qnngpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.QnnGpuPrecision.K_GPU_USER_PROVIDED"]], "k_htp_balanced (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_BALANCED"]], "k_htp_burst (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_BURST"]], "k_htp_fp16 (qnnhtpprecision attribute)": [[61, "netspresso.np_qai.options.profile.QnnHtpPrecision.K_HTP_FP16"]], "k_htp_high_performance (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_HIGH_PERFORMANCE"]], "k_htp_high_power_saver (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_HIGH_POWER_SAVER"]], "k_htp_low_balanced (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_LOW_BALANCED"]], "k_htp_low_power_saver (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_LOW_POWER_SAVER"]], "k_htp_optimize_for_inference (qnnhtpoptimizationstrategy attribute)": [[61, "netspresso.np_qai.options.profile.QnnHtpOptimizationStrategy.K_HTP_OPTIMIZE_FOR_INFERENCE"]], "k_htp_optimize_for_prepare (qnnhtpoptimizationstrategy attribute)": [[61, "netspresso.np_qai.options.profile.QnnHtpOptimizationStrategy.K_HTP_OPTIMIZE_FOR_PREPARE"]], "k_htp_power_saver (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_POWER_SAVER"]], "k_htp_quantized (qnnhtpprecision attribute)": [[61, "netspresso.np_qai.options.profile.QnnHtpPrecision.K_HTP_QUANTIZED"]], "k_htp_sustained_high_performance (tfliteqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode.K_HTP_SUSTAINED_HIGH_PERFORMANCE"]], "k_log_level_debug (qnnloglevel attribute)": [[61, "netspresso.np_qai.options.profile.QnnLogLevel.K_LOG_LEVEL_DEBUG"]], "k_log_level_error (qnnloglevel attribute)": [[61, "netspresso.np_qai.options.profile.QnnLogLevel.K_LOG_LEVEL_ERROR"]], "k_log_level_info (qnnloglevel attribute)": [[61, "netspresso.np_qai.options.profile.QnnLogLevel.K_LOG_LEVEL_INFO"]], "k_log_level_verbose (qnnloglevel attribute)": [[61, "netspresso.np_qai.options.profile.QnnLogLevel.K_LOG_LEVEL_VERBOSE"]], "k_log_level_warn (qnnloglevel attribute)": [[61, "netspresso.np_qai.options.profile.QnnLogLevel.K_LOG_LEVEL_WARN"]], "k_log_off (qnnloglevel attribute)": [[61, "netspresso.np_qai.options.profile.QnnLogLevel.K_LOG_OFF"]], "k_low_power (nnapiexecutionpreference attribute)": [[61, "netspresso.np_qai.options.profile.NnapiExecutionPreference.K_LOW_POWER"]], "k_qnn_priority_default (qnngraphpriority attribute)": [[61, "netspresso.np_qai.options.profile.QnnGraphPriority.K_QNN_PRIORITY_DEFAULT"]], "k_qnn_priority_high (qnngraphpriority attribute)": [[61, "netspresso.np_qai.options.profile.QnnGraphPriority.K_QNN_PRIORITY_HIGH"]], "k_qnn_priority_low (qnngraphpriority attribute)": [[61, "netspresso.np_qai.options.profile.QnnGraphPriority.K_QNN_PRIORITY_LOW"]], "k_qnn_priority_normal (qnngraphpriority attribute)": [[61, "netspresso.np_qai.options.profile.QnnGraphPriority.K_QNN_PRIORITY_NORMAL"]], "k_qnn_priority_normal_high (qnngraphpriority attribute)": [[61, "netspresso.np_qai.options.profile.QnnGraphPriority.K_QNN_PRIORITY_NORMAL_HIGH"]], "k_qnn_priority_undefined (qnngraphpriority attribute)": [[61, "netspresso.np_qai.options.profile.QnnGraphPriority.K_QNN_PRIORITY_UNDEFINED"]], "k_sustained_speed (nnapiexecutionpreference attribute)": [[61, "netspresso.np_qai.options.profile.NnapiExecutionPreference.K_SUSTAINED_SPEED"]], "low (contextgpuperformancehint attribute)": [[61, "netspresso.np_qai.options.profile.ContextGpuPerformanceHint.LOW"]], "low (priority attribute)": [[61, "netspresso.np_qai.options.profile.Priority.LOW"]], "low_balanced (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.LOW_BALANCED"]], "low_balanced (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.LOW_BALANCED"]], "low_power_saver (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.LOW_POWER_SAVER"]], "low_power_saver (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.LOW_POWER_SAVER"]], "nnapi (tflitedelegates attribute)": [[61, "netspresso.np_qai.options.profile.TfliteDelegates.NNAPI"]], "nnapi_gpu (tflitedelegates attribute)": [[61, "netspresso.np_qai.options.profile.TfliteDelegates.NNAPI_GPU"]], "normal (contextgpuperformancehint attribute)": [[61, "netspresso.np_qai.options.profile.ContextGpuPerformanceHint.NORMAL"]], "normal (priority attribute)": [[61, "netspresso.np_qai.options.profile.Priority.NORMAL"]], "normal_high (priority attribute)": [[61, "netspresso.np_qai.options.profile.Priority.NORMAL_HIGH"]], "nnapiexecutionpreference (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.NnapiExecutionPreference"]], "onnxexecutionproviders (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.OnnxExecutionProviders"]], "onnxoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.OnnxOptions"]], "onnxqnnhtpperformancemode (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode"]], "onnxqnnoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.OnnxQnnOptions"]], "parallel (executionmode attribute)": [[61, "netspresso.np_qai.options.profile.ExecutionMode.PARALLEL"]], "power_saver (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.POWER_SAVER"]], "power_saver (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.POWER_SAVER"]], "priority (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.Priority"]], "profilecommonoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions"]], "profileoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.ProfileOptions"]], "qnn (onnxexecutionproviders attribute)": [[61, "netspresso.np_qai.options.profile.OnnxExecutionProviders.QNN"]], "qnn (tflitedelegates attribute)": [[61, "netspresso.np_qai.options.profile.TfliteDelegates.QNN"]], "qnn_gpu (onnxexecutionproviders attribute)": [[61, "netspresso.np_qai.options.profile.OnnxExecutionProviders.QNN_GPU"]], "qnn_gpu (tflitedelegates attribute)": [[61, "netspresso.np_qai.options.profile.TfliteDelegates.QNN_GPU"]], "qnndspencoding (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnDspEncoding"]], "qnndspperformancemode (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnDspPerformanceMode"]], "qnngpuperformancemode (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnGpuPerformanceMode"]], "qnngpuprecision (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnGpuPrecision"]], "qnngraphpriority (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnGraphPriority"]], "qnnhtpoptimizationstrategy (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnHtpOptimizationStrategy"]], "qnnhtpprecision (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnHtpPrecision"]], "qnnloglevel (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnLogLevel"]], "qnnoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.QnnOptions"]], "sequential (executionmode attribute)": [[61, "netspresso.np_qai.options.profile.ExecutionMode.SEQUENTIAL"]], "sustained_high_performance (contexthtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.ContextHtpPerformanceMode.SUSTAINED_HIGH_PERFORMANCE"]], "sustained_high_performance (onnxqnnhtpperformancemode attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnHtpPerformanceMode.SUSTAINED_HIGH_PERFORMANCE"]], "tflite_gpu_inference_preference_balanced (gpuinferencepreference attribute)": [[61, "netspresso.np_qai.options.profile.GpuInferencePreference.TFLITE_GPU_INFERENCE_PREFERENCE_BALANCED"]], "tflite_gpu_inference_preference_balanced (gpuinferencepriority attribute)": [[61, "netspresso.np_qai.options.profile.GpuInferencePriority.TFLITE_GPU_INFERENCE_PREFERENCE_BALANCED"]], "tflite_gpu_inference_preference_fast_single_answer (gpuinferencepreference attribute)": [[61, "netspresso.np_qai.options.profile.GpuInferencePreference.TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER"]], "tflite_gpu_inference_preference_sustained_speed (gpuinferencepreference attribute)": [[61, "netspresso.np_qai.options.profile.GpuInferencePreference.TFLITE_GPU_INFERENCE_PREFERENCE_SUSTAINED_SPEED"]], "tflite_gpu_inference_priority_max_precision (gpuinferencepriority attribute)": [[61, "netspresso.np_qai.options.profile.GpuInferencePriority.TFLITE_GPU_INFERENCE_PRIORITY_MAX_PRECISION"]], "tflite_gpu_inference_priority_min_latency (gpuinferencepriority attribute)": [[61, "netspresso.np_qai.options.profile.GpuInferencePriority.TFLITE_GPU_INFERENCE_PRIORITY_MIN_LATENCY"]], "tflite_gpu_inference_priority_min_memory_usage (gpuinferencepriority attribute)": [[61, "netspresso.np_qai.options.profile.GpuInferencePriority.TFLITE_GPU_INFERENCE_PRIORITY_MIN_MEMORY_USAGE"]], "tflitedelegates (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.TfliteDelegates"]], "tflitegpuv2options (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.TfliteGpuv2Options"]], "tflitennapioptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.TfliteNnapiOptions"]], "tfliteoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.TfliteOptions"]], "tfliteqnnhtpperformancemode (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.TfliteQnnHtpPerformanceMode"]], "tfliteqnnoptions (class in netspresso.np_qai.options.profile)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions"]], "user_provided (defaultgraphgpuprecision attribute)": [[61, "netspresso.np_qai.options.profile.DefaultGraphGpuPrecision.USER_PROVIDED"]], "xnnpack (tflitedelegates attribute)": [[61, "netspresso.np_qai.options.profile.TfliteDelegates.XNNPACK"]], "allow_fp32_as_fp16 (tfliteoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteOptions.allow_fp32_as_fp16"]], "context_async_execution_queue_depth_numeric (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_async_execution_queue_depth_numeric"]], "context_enable_graphs (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_enable_graphs"]], "context_error_reporting_options_level (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_error_reporting_options_level"]], "context_error_reporting_options_storage_limit (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_error_reporting_options_storage_limit"]], "context_gpu_performance_hint (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_gpu_performance_hint"]], "context_gpu_use_gl_buffers (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_gpu_use_gl_buffers"]], "context_htp_performance_mode (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_htp_performance_mode"]], "context_memory_limit_hint (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_memory_limit_hint"]], "context_priority (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.context_priority"]], "default_graph_gpu_disable_memory_optimizations (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_gpu_disable_memory_optimizations"]], "default_graph_gpu_disable_node_optimizations (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_gpu_disable_node_optimizations"]], "default_graph_gpu_disable_queue_recording (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_gpu_disable_queue_recording"]], "default_graph_gpu_precision (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_gpu_precision"]], "default_graph_htp_disable_fold_relu_activation_into_conv (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_htp_disable_fold_relu_activation_into_conv"]], "default_graph_htp_disable_short_depth_conv_on_hmx (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_htp_disable_short_depth_conv_on_hmx"]], "default_graph_htp_num_hvx_threads (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_htp_num_hvx_threads"]], "default_graph_htp_optimization_type (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_htp_optimization_type"]], "default_graph_htp_optimization_value (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_htp_optimization_value"]], "default_graph_htp_precision (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_htp_precision"]], "default_graph_htp_vtcm_size (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_htp_vtcm_size"]], "default_graph_priority (qnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.QnnOptions.default_graph_priority"]], "dequantize_outputs (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.dequantize_outputs"]], "enable_cpu_memory_arena (onnxoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxOptions.enable_cpu_memory_arena"]], "enable_fallback (tfliteoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteOptions.enable_fallback"]], "enable_memory_pattern (onnxoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxOptions.enable_memory_pattern"]], "execution_mode (onnxoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxOptions.execution_mode"]], "force_opengl (tfliteoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteOptions.force_opengl"]], "gpu_inference_preference (tflitegpuv2options attribute)": [[61, "netspresso.np_qai.options.profile.TfliteGpuv2Options.gpu_inference_preference"]], "gpu_inference_priority1 (tflitegpuv2options attribute)": [[61, "netspresso.np_qai.options.profile.TfliteGpuv2Options.gpu_inference_priority1"]], "gpu_inference_priority2 (tflitegpuv2options attribute)": [[61, "netspresso.np_qai.options.profile.TfliteGpuv2Options.gpu_inference_priority2"]], "gpu_inference_priority3 (tflitegpuv2options attribute)": [[61, "netspresso.np_qai.options.profile.TfliteGpuv2Options.gpu_inference_priority3"]], "gpu_max_delegated_partitions (tflitegpuv2options attribute)": [[61, "netspresso.np_qai.options.profile.TfliteGpuv2Options.gpu_max_delegated_partitions"]], "graph_optimization_level (onnxoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxOptions.graph_optimization_level"]], "handle_common_options() (profilecommonoptions method)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.handle_common_options"]], "handle_onnx_options() (profilecommonoptions method)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.handle_onnx_options"]], "handle_qnn_options() (profilecommonoptions method)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.handle_qnn_options"]], "handle_tflite_options() (profilecommonoptions method)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.handle_tflite_options"]], "inter_op_num_threads (onnxoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxOptions.inter_op_num_threads"]], "intra_op_num_threads (onnxoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxOptions.intra_op_num_threads"]], "invoke_interpreter_on_cold_load (tfliteoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteOptions.invoke_interpreter_on_cold_load"]], "max_profiler_iterations (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.max_profiler_iterations"]], "max_profiler_time (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.max_profiler_time"]], "netspresso.np_qai.options.profile": [[61, "module-netspresso.np_qai.options.profile"]], "nnapi_allow_fp16 (tflitennapioptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteNnapiOptions.nnapi_allow_fp16"]], "nnapi_execution_preference (tflitennapioptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteNnapiOptions.nnapi_execution_preference"]], "nnapi_max_number_delegated_partitions (tflitennapioptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteNnapiOptions.nnapi_max_number_delegated_partitions"]], "number_of_threads (tfliteoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteOptions.number_of_threads"]], "onnx_execution_providers (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.onnx_execution_providers"]], "onnx_options (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.onnx_options"]], "qnn_dsp_encoding (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_dsp_encoding"]], "qnn_dsp_performance_mode (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_dsp_performance_mode"]], "qnn_enable_htp_fp16_precision (onnxqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnOptions.qnn_enable_htp_fp16_precision"]], "qnn_gpu_performance_mode (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_gpu_performance_mode"]], "qnn_gpu_precision (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_gpu_precision"]], "qnn_graph_priority (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_graph_priority"]], "qnn_htp_graph_optimization_mode (onnxqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnOptions.qnn_htp_graph_optimization_mode"]], "qnn_htp_num_hvx_threads (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_htp_num_hvx_threads"]], "qnn_htp_optimization_strategy (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_htp_optimization_strategy"]], "qnn_htp_performance_mode (onnxqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.OnnxQnnOptions.qnn_htp_performance_mode"]], "qnn_htp_performance_mode (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_htp_performance_mode"]], "qnn_htp_precision (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_htp_precision"]], "qnn_htp_use_conv_hmx (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_htp_use_conv_hmx"]], "qnn_htp_use_fold_relu (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_htp_use_fold_relu"]], "qnn_htp_vtcm_size (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_htp_vtcm_size"]], "qnn_log_level (tfliteqnnoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.qnn_log_level"]], "qnn_options (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.qnn_options"]], "release_dynamic_tensors (tfliteoptions attribute)": [[61, "netspresso.np_qai.options.profile.TfliteOptions.release_dynamic_tensors"]], "tflite_delegates (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.tflite_delegates"]], "tflite_options (profilecommonoptions attribute)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.tflite_options"]], "to_cli_string() (onnxoptions method)": [[61, "netspresso.np_qai.options.profile.OnnxOptions.to_cli_string"]], "to_cli_string() (onnxqnnoptions method)": [[61, "netspresso.np_qai.options.profile.OnnxQnnOptions.to_cli_string"]], "to_cli_string() (profilecommonoptions method)": [[61, "netspresso.np_qai.options.profile.ProfileCommonOptions.to_cli_string"]], "to_cli_string() (qnnoptions method)": [[61, "netspresso.np_qai.options.profile.QnnOptions.to_cli_string"]], "to_cli_string() (tflitegpuv2options method)": [[61, "netspresso.np_qai.options.profile.TfliteGpuv2Options.to_cli_string"]], "to_cli_string() (tflitennapioptions method)": [[61, "netspresso.np_qai.options.profile.TfliteNnapiOptions.to_cli_string"]], "to_cli_string() (tfliteoptions method)": [[61, "netspresso.np_qai.options.profile.TfliteOptions.to_cli_string"]], "to_cli_string() (tfliteqnnoptions method)": [[61, "netspresso.np_qai.options.profile.TfliteQnnOptions.to_cli_string"]], "auto (rangescheme attribute)": [[62, "netspresso.np_qai.options.quantize.RangeScheme.AUTO"]], "int16 (quantizeprecision attribute)": [[62, "netspresso.np_qai.options.quantize.QuantizePrecision.INT16"]], "int4 (quantizeprecision attribute)": [[62, "netspresso.np_qai.options.quantize.QuantizePrecision.INT4"]], "int8 (quantizeprecision attribute)": [[62, "netspresso.np_qai.options.quantize.QuantizePrecision.INT8"]], "min_max (rangescheme attribute)": [[62, "netspresso.np_qai.options.quantize.RangeScheme.MIN_MAX"]], "mse_minimizer (rangescheme attribute)": [[62, "netspresso.np_qai.options.quantize.RangeScheme.MSE_MINIMIZER"]], "quantizeoptions (class in netspresso.np_qai.options.quantize)": [[62, "netspresso.np_qai.options.quantize.QuantizeOptions"]], "quantizeprecision (class in netspresso.np_qai.options.quantize)": [[62, "netspresso.np_qai.options.quantize.QuantizePrecision"]], "rangescheme (class in netspresso.np_qai.options.quantize)": [[62, "netspresso.np_qai.options.quantize.RangeScheme"]], "netspresso.np_qai.options.quantize": [[62, "module-netspresso.np_qai.options.quantize"]], "range_scheme (quantizeoptions attribute)": [[62, "netspresso.np_qai.options.quantize.QuantizeOptions.range_scheme"]], "to_cli_string() (quantizeoptions method)": [[62, "netspresso.np_qai.options.quantize.QuantizeOptions.to_cli_string"]], "download_model() (in module netspresso.np_qai.quantizer.npqaiquantizer)": [[63, "netspresso.np_qai.quantizer.NPQAIQuantizer.download_model"]], "get_quantize_task_status() (in module netspresso.np_qai.quantizer.npqaiquantizer)": [[64, "netspresso.np_qai.quantizer.NPQAIQuantizer.get_quantize_task_status"]], "quantize_model() (in module netspresso.np_qai.quantizer.npqaiquantizer)": [[65, "netspresso.np_qai.quantizer.NPQAIQuantizer.quantize_model"]], "update_quantize_task() (in module netspresso.np_qai.quantizer.npqaiquantizer)": [[67, "netspresso.np_qai.quantizer.NPQAIQuantizer.update_quantize_task"]], "automatic_quantization() (in module netspresso.quantizer.__init__.quantizer)": [[68, "netspresso.quantizer.__init__.Quantizer.automatic_quantization"]], "custom_precision_quantization_by_layer_name() (in module netspresso.quantizer.__init__.quantizer)": [[69, "netspresso.quantizer.__init__.Quantizer.custom_precision_quantization_by_layer_name"]], "custom_precision_quantization_by_operator_type() (in module netspresso.quantizer.__init__.quantizer)": [[70, "netspresso.quantizer.__init__.Quantizer.custom_precision_quantization_by_operator_type"]], "get_recommendation_precision() (in module netspresso.quantizer.__init__.quantizer)": [[71, "netspresso.quantizer.__init__.Quantizer.get_recommendation_precision"]], "uniform_precision_quantization() (in module netspresso.quantizer.__init__.quantizer)": [[72, "netspresso.quantizer.__init__.Quantizer.uniform_precision_quantization"]], "trainer (class in netspresso.trainer.trainer)": [[74, "netspresso.trainer.trainer.Trainer"]], "set_augmentation_config() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.set_augmentation_config"]], "set_dataset_config() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.set_dataset_config"]], "set_environment_config() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.set_environment_config"]], "set_fx_model() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.set_fx_model"]], "set_logging_config() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.set_logging_config"]], "set_model_config() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.set_model_config"]], "set_training_config() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.set_training_config"]], "train() (trainer method)": [[74, "netspresso.trainer.trainer.Trainer.train"]]}})